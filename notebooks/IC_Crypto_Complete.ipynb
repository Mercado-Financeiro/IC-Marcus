{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f2f3bb",
   "metadata": {},
   "source": [
    "# IC Crypto Complete - Pipeline ML para Trading de Criptomoedas\n",
    "\n",
    "Pipeline completo de Machine Learning para trading de criptomoedas com:\n",
    "- Labeling adaptativo baseado em volatilidade\n",
    "- Múltiplos horizontes de predição (15m, 30m, 60m, 120m)\n",
    "- Features específicas para mercado 24/7\n",
    "- Backtest realista com custos e execução t+1\n",
    "- Otimização Bayesiana com Optuna\n",
    "- Calibração de probabilidades\n",
    "- MLflow tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528cac0",
   "metadata": {},
   "source": [
    "## 1. Setup Completo - Imports e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33823ff1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Optuna não disponível\n",
      "⚠️ TA-Lib não disponível\n",
      "⚠️ Imports locais não disponíveis - usando implementações do notebook\n",
      "✅ Imports concluídos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ========================== IMPORTS ORGANIZADOS ==========================\n",
    "\n",
    "# Standard Library\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import hashlib\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "\n",
    "# Configurar warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Machine Learning - Scikit-learn\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, matthews_corrcoef,\n",
    "    confusion_matrix, classification_report, roc_curve,\n",
    "    precision_recall_curve, brier_score_loss, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"⚠️ XGBoost não disponível\")\n",
    "\n",
    "# Optuna\n",
    "OPTUNA_AVAILABLE = False\n",
    "OPTUNA_XGBOOST_INTEGRATION = False\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna.pruners import MedianPruner, SuccessiveHalvingPruner, HyperbandPruner\n",
    "    from optuna.samplers import TPESampler\n",
    "    OPTUNA_AVAILABLE = True\n",
    "    print(\"✅ Optuna core disponível\")\n",
    "    \n",
    "    # Tentar carregar integração XGBoost separadamente\n",
    "    try:\n",
    "        from optuna.integration import XGBoostPruningCallback\n",
    "        OPTUNA_XGBOOST_INTEGRATION = True\n",
    "        print(\"✅ Optuna XGBoost integration disponível\")\n",
    "    except ImportError as e:\n",
    "        print(f\"⚠️ Optuna XGBoost integration não disponível: {e}\")\n",
    "        print(\"   Pipeline continuará com otimização básica\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"⚠️ Optuna não disponível: {e}\")\n",
    "    print(\"   Pipeline continuará com hiperparâmetros padrão\")\n",
    "\n",
    "# Deep Learning - PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    TORCH_AVAILABLE = True\n",
    "    \n",
    "    # Configurar determinismo do PyTorch\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"⚠️ PyTorch não disponível\")\n",
    "\n",
    "# MLflow\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.xgboost\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"⚠️ MLflow não disponível\")\n",
    "\n",
    "# SHAP\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"⚠️ SHAP não disponível\")\n",
    "\n",
    "# Data APIs\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    YFINANCE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    YFINANCE_AVAILABLE = False\n",
    "    print(\"⚠️ yfinance não disponível\")\n",
    "\n",
    "try:\n",
    "    import ccxt\n",
    "    CCXT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CCXT_AVAILABLE = False\n",
    "    print(\"⚠️ CCXT não disponível\")\n",
    "\n",
    "# Technical Analysis\n",
    "try:\n",
    "    import ta\n",
    "    TA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TA_AVAILABLE = False\n",
    "    print(\"⚠️ TA-Lib não disponível\")\n",
    "\n",
    "# Data Validation\n",
    "try:\n",
    "    import pandera as pa\n",
    "    from pandera import Column, DataFrameSchema, Check\n",
    "    PANDERA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PANDERA_AVAILABLE = False\n",
    "    print(\"⚠️ Pandera não disponível\")\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    from plotly.subplots import make_subplots\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"⚠️ Plotly não disponível\")\n",
    "\n",
    "# Imports locais do projeto (quando disponíveis)\n",
    "try:\n",
    "    from src.data.binance_loader import CryptoDataLoader\n",
    "    from src.data.splits import PurgedKFold as ImportedPurgedKFold\n",
    "    from src.features.engineering import FeatureEngineer as BaseFeatureEngineer\n",
    "    from src.models.xgb_optuna import XGBoostOptuna as ImportedXGBoostOptuna\n",
    "    from src.backtest.engine import BacktestEngine as ImportedBacktestEngine, BacktestConfig\n",
    "    LOCAL_IMPORTS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LOCAL_IMPORTS_AVAILABLE = False\n",
    "    print(\"⚠️ Imports locais não disponíveis - usando implementações do notebook\")\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "\n",
    "print(\"✅ Imports concluídos com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4826e",
   "metadata": {},
   "source": [
    "## 2. Fallbacks para Bibliotecas Opcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791abc0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class FallbackPruningCallback:\n",
    "    \"\"\"Fallback para XGBoostPruningCallback quando optuna-integration não disponível\"\"\"\n",
    "    def __init__(self, trial, metric_name):\n",
    "        self.trial = trial\n",
    "        self.metric_name = metric_name\n",
    "        \n",
    "    def __call__(self, env):\n",
    "        \"\"\"Callback compatível com XGBoost\"\"\"\n",
    "        # Extrair métrica de validação\n",
    "        if hasattr(env, 'evaluation_result_list') and env.evaluation_result_list:\n",
    "            # Formato: [('validation_0', 'aucpr', value)]\n",
    "            for eval_name, metric, value in env.evaluation_result_list:\n",
    "                if metric in self.metric_name or self.metric_name in metric:\n",
    "                    self.trial.report(value, env.iteration)\n",
    "                    if self.trial.should_prune():\n",
    "                        raise optuna.TrialPruned()\n",
    "        return False\n",
    "\n",
    "def create_xgb_pruning_callback(trial, metric_name):\n",
    "    \"\"\"Factory function para criar callback apropriado\"\"\"\n",
    "    if OPTUNA_XGBOOST_INTEGRATION:\n",
    "        from optuna.integration import XGBoostPruningCallback\n",
    "        return XGBoostPruningCallback(trial, metric_name)\n",
    "    elif OPTUNA_AVAILABLE:\n",
    "        return FallbackPruningCallback(trial, metric_name)\n",
    "    else:\n",
    "        # Retorna callback dummy que não faz nada\n",
    "        return lambda env: False\n",
    "\n",
    "def safe_optuna_study(direction='maximize', sampler=None, pruner=None):\n",
    "    \"\"\"Criar study do Optuna com fallbacks\"\"\"\n",
    "    if OPTUNA_AVAILABLE:\n",
    "        return optuna.create_study(\n",
    "            direction=direction,\n",
    "            sampler=sampler or optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=pruner or optuna.pruners.MedianPruner()\n",
    "        )\n",
    "    else:\n",
    "        # Fallback: usar grid search simples\n",
    "        print(\"⚠️ Usando grid search básico no lugar do Optuna\")\n",
    "        return None\n",
    "\n",
    "def safe_mlflow_log(func_name, *args, **kwargs):\n",
    "    \"\"\"Helper para fazer log no MLflow de forma segura\"\"\"\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        import mlflow\n",
    "        func = getattr(mlflow, func_name)\n",
    "        return func(*args, **kwargs)\n",
    "    return None\n",
    "\n",
    "def safe_mlflow_start_run(**kwargs):\n",
    "    \"\"\"Helper para iniciar run do MLflow de forma segura\"\"\"\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        import mlflow\n",
    "        return mlflow.start_run(**kwargs)\n",
    "    return None\n",
    "\n",
    "def safe_mlflow_end_run():\n",
    "    \"\"\"Helper para finalizar run do MLflow de forma segura\"\"\"\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        import mlflow\n",
    "        return mlflow.end_run()\n",
    "    return None\n",
    "\n",
    "print(\"✅ Fallbacks configurados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480505f",
   "metadata": {},
   "source": [
    "## 3. Configuração Determinística do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f8f09a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ambiente configurado para determinismo com seed=42\n",
      "   PYTHONHASHSEED=42\n"
     ]
    }
   ],
   "source": [
    "def setup_deterministic_environment(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Configura ambiente para reprodutibilidade total\n",
    "    \"\"\"\n",
    "    # Python built-in\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Scikit-learn (se aplicável)\n",
    "    os.environ['SKLEARN_SEED'] = str(seed)\n",
    "    \n",
    "    # PyTorch (se disponível)\n",
    "    if TORCH_AVAILABLE:\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "            # Para operações determinísticas em GPU\n",
    "            os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "            os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "    \n",
    "    # TensorFlow (se disponível)\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        tf.random.set_seed(seed)\n",
    "        os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    print(f\"✅ Ambiente configurado para determinismo com seed={seed}\")\n",
    "    print(f\"   PYTHONHASHSEED={os.environ.get('PYTHONHASHSEED', 'not set')}\")\n",
    "    if TORCH_AVAILABLE and torch.cuda.is_available():\n",
    "        print(f\"   CUDA determinístico: {torch.backends.cudnn.deterministic}\")\n",
    "        print(f\"   CUBLAS_WORKSPACE_CONFIG={os.environ.get('CUBLAS_WORKSPACE_CONFIG', 'not set')}\")\n",
    "    \n",
    "    return seed\n",
    "\n",
    "# Aplicar configuração determinística\n",
    "GLOBAL_SEED = setup_deterministic_environment(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c82713",
   "metadata": {},
   "source": [
    "## 3. Configurações Globais do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "666b0857",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Diretórios criados\n",
      "✅ MLflow configurado: artifacts/mlruns\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class ProjectConfig:\n",
    "    \"\"\"Configurações globais do projeto\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    data_path: str = \"data\"\n",
    "    artifacts_path: str = \"artifacts\"\n",
    "    models_path: str = \"artifacts/models\"\n",
    "    reports_path: str = \"artifacts/reports\"\n",
    "    mlflow_tracking_uri: str = \"artifacts/mlruns\"\n",
    "    \n",
    "    # Data\n",
    "    symbol: str = \"BTCUSDT\"\n",
    "    timeframe: str = \"15m\"\n",
    "    start_date: str = \"2023-01-01\"\n",
    "    end_date: str = \"2024-01-01\"\n",
    "    \n",
    "    # Funding periods por símbolo (em minutos)\n",
    "    # Fonte: https://www.binance.com/en/support/faq/detail/360033525031\n",
    "    # Padrão: 480 min (8h) para maioria dos contratos perpétuos\n",
    "    # Alguns contratos específicos usam 60 min (1h) ou 240 min (4h)\n",
    "    FUNDING_MIN_BY_SYMBOL: Dict[str, int] = field(default_factory=lambda: {\n",
    "        \"BTCUSDT\": 480,    # 8 horas\n",
    "        \"ETHUSDT\": 480,    # 8 horas  \n",
    "        \"BNBUSDT\": 480,    # 8 horas\n",
    "        \"SOLUSDT\": 480,    # 8 horas\n",
    "        \"XRPUSDT\": 480,    # 8 horas\n",
    "        \"ADAUSDT\": 480,    # 8 horas\n",
    "        # Adicionar outros símbolos conforme necessário\n",
    "        # Alguns contratos exóticos podem ter 60 ou 240 minutos\n",
    "    })\n",
    "    \n",
    "    # Horizontes de predição (em barras de 15min)\n",
    "    horizons: Dict[str, int] = None\n",
    "    \n",
    "    # Features\n",
    "    feature_windows: List[int] = None\n",
    "    volatility_estimators: List[str] = None\n",
    "    \n",
    "    # Model\n",
    "    test_size: float = 0.2\n",
    "    val_size: float = 0.2\n",
    "    cv_splits: int = 5\n",
    "    embargo_bars: int = 10\n",
    "    \n",
    "    # Trading\n",
    "    initial_capital: float = 100000\n",
    "    fee_bps: float = 5  # basis points\n",
    "    slippage_bps: float = 10\n",
    "    max_leverage: float = 1.0\n",
    "    funding_period_minutes: int = 480  # período de funding em minutos (8 horas por padrão)\n",
    "    \n",
    "    # Optimization\n",
    "    n_trials_optuna: int = 50\n",
    "    optuna_timeout: int = 3600  # seconds\n",
    "    \n",
    "    # MLflow\n",
    "    experiment_name: str = \"crypto_ml_trading\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Inicializar valores padrão para campos mutáveis\"\"\"\n",
    "        if self.horizons is None:\n",
    "            # Calcular horizonte de funding dinamicamente\n",
    "            funding_horizon_bars = self.funding_period_minutes // 15  # converter para barras de 15min\n",
    "            self.horizons = {\n",
    "                '15m': 1,   # 15 minutos\n",
    "                '30m': 2,   # 30 minutos  \n",
    "                '60m': 4,   # 1 hora\n",
    "                '120m': 8,  # 2 horas\n",
    "                '240m': 16, # 4 horas\n",
    "                f'{self.funding_period_minutes}m': funding_horizon_bars  # funding cycle dinâmico\n",
    "            }\n",
    "        \n",
    "        if self.feature_windows is None:\n",
    "            self.feature_windows = [5, 10, 20, 50, 100, 200]\n",
    "        \n",
    "        if self.volatility_estimators is None:\n",
    "            self.volatility_estimators = ['atr', 'garman_klass', 'yang_zhang', 'parkinson']\n",
    "    \n",
    "    def create_directories(self):\n",
    "        \"\"\"Criar estrutura de diretórios\"\"\"\n",
    "        for path in [self.data_path, self.artifacts_path, self.models_path, self.reports_path]:\n",
    "            Path(path).mkdir(parents=True, exist_ok=True)\n",
    "        print(\"✅ Diretórios criados\")\n",
    "\n",
    "# Instanciar configuração global\n",
    "config = ProjectConfig()\n",
    "config.create_directories()\n",
    "\n",
    "# Configurar MLflow\n",
    "if MLFLOW_AVAILABLE:\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(config.mlflow_tracking_uri)\n",
    "    mlflow.set_experiment(config.experiment_name)\n",
    "    print(f\"✅ MLflow configurado: {config.mlflow_tracking_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ff321",
   "metadata": {},
   "source": [
    "## 4. Classes de Estimadores de Volatilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daebc14c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Classe VolatilityEstimators definida\n"
     ]
    }
   ],
   "source": [
    "class VolatilityEstimators:\n",
    "    \"\"\"\n",
    "    Implementação de diversos estimadores de volatilidade para mercados 24/7\n",
    "    Referência: Sinclair (2008) - Volatility Trading\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def atr(df: pd.DataFrame, window: int = 14) -> pd.Series:\n",
    "        \"\"\"Average True Range - robusto para gaps\"\"\"\n",
    "        high = df['high']\n",
    "        low = df['low']\n",
    "        close = df['close']\n",
    "        \n",
    "        tr1 = high - low\n",
    "        tr2 = abs(high - close.shift())\n",
    "        tr3 = abs(low - close.shift())\n",
    "        \n",
    "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "        atr = tr.rolling(window=window).mean()\n",
    "        \n",
    "        # Normalizar como proporção do preço (retorno implícito)\n",
    "        return atr / close\n",
    "    \n",
    "    @staticmethod\n",
    "    def garman_klass(df: pd.DataFrame, window: int = 14) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Garman-Klass estimator (1980)\n",
    "        Usa OHLC, ~8x mais eficiente que close-to-close\n",
    "        \"\"\"\n",
    "        log_hl = np.log(df['high'] / df['low'])\n",
    "        log_co = np.log(df['close'] / df['open'])\n",
    "        \n",
    "        gk = np.sqrt(\n",
    "            0.5 * log_hl**2 - \n",
    "            (2 * np.log(2) - 1) * log_co**2\n",
    "        )\n",
    "        \n",
    "        # Normalizar para escala comparável ao ATR (retorno fracionário)\n",
    "        gk_mean = gk.rolling(window=window).mean()\n",
    "        return gk_mean.clip(lower=1e-8)  # Evitar divisão por zero\n",
    "    \n",
    "    @staticmethod  \n",
    "    def yang_zhang(df: pd.DataFrame, window: int = 14) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Yang-Zhang estimator (2000)\n",
    "        Melhor estimador para drift e gaps\n",
    "        \"\"\"\n",
    "        log_ho = np.log(df['high'] / df['open'])\n",
    "        log_lo = np.log(df['low'] / df['open'])\n",
    "        log_co = np.log(df['close'] / df['open'])\n",
    "        \n",
    "        log_oc = np.log(df['open'] / df['close'].shift())\n",
    "        log_oc_mean = log_oc.rolling(window=window).mean()\n",
    "        \n",
    "        log_cc = np.log(df['close'] / df['close'].shift())\n",
    "        log_cc_mean = log_cc.rolling(window=window).mean()\n",
    "        \n",
    "        # Volatilidade overnight\n",
    "        vol_overnight = (log_oc - log_oc_mean)**2\n",
    "        vol_overnight = vol_overnight.rolling(window=window).mean()\n",
    "        \n",
    "        # Volatilidade close-to-close\n",
    "        vol_cc = (log_cc - log_cc_mean)**2\n",
    "        vol_cc = vol_cc.rolling(window=window).mean()\n",
    "        \n",
    "        # Volatilidade Rogers-Satchell\n",
    "        rs = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)\n",
    "        vol_rs = rs.rolling(window=window).mean()\n",
    "        \n",
    "        # Combinar com pesos ótimos\n",
    "        k = 0.34 / (1.34 + (window + 1) / (window - 1))\n",
    "        yz = np.sqrt(vol_overnight + k * vol_cc + (1 - k) * vol_rs)\n",
    "        \n",
    "        # Normalizar para escala comparável (retorno fracionário)\n",
    "        # Yang-Zhang já está em escala de log-retorno, clipar para evitar zero\n",
    "        return yz.clip(lower=1e-8)\n",
    "    \n",
    "    @staticmethod\n",
    "    def parkinson(df: pd.DataFrame, window: int = 14) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Parkinson estimator (1980)\n",
    "        Usa high-low, ~5x mais eficiente que close-to-close\n",
    "        \"\"\"\n",
    "        log_hl = np.log(df['high'] / df['low'])\n",
    "        park = log_hl / (2 * np.sqrt(np.log(2)))\n",
    "        \n",
    "        # Normalizar para escala comparável (retorno fracionário)\n",
    "        park_mean = park.rolling(window=window).mean()\n",
    "        return park_mean.clip(lower=1e-8)  # Evitar divisão por zero\n",
    "    \n",
    "    @staticmethod\n",
    "    def realized_volatility(df: pd.DataFrame, window: int = 14) -> pd.Series:\n",
    "        \"\"\"Volatilidade realizada clássica\"\"\"\n",
    "        returns = np.log(df['close'] / df['close'].shift())\n",
    "        return returns.rolling(window=window).std()\n",
    "\n",
    "print(\"✅ Classe VolatilityEstimators definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14e03f",
   "metadata": {},
   "source": [
    "## 5. Sistema de Labeling Adaptativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4091405",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Classe AdaptiveLabeler definida\n"
     ]
    }
   ],
   "source": [
    "class AdaptiveLabeler:\n",
    "    \"\"\"\n",
    "    Sistema de rotulagem adaptativo baseado em volatilidade\n",
    "    Sistema mais robusto e interpretável para mercados 24/7\n",
    "    Suporta múltiplos horizontes alinhados com timeframe de 15m\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 horizon_bars: int = 4,  # 1h em dados de 15min\n",
    "                 k: float = 1.0,  # Multiplicador do threshold\n",
    "                 vol_estimator: str = 'atr',  # Estimador de volatilidade\n",
    "                 neutral_zone: bool = True):  # Usar zona neutra\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            horizon_bars: Janela futura para calcular retorno\n",
    "            k: Multiplicador do threshold (hiperparâmetro a otimizar)\n",
    "            vol_estimator: 'atr', 'garman_klass', 'yang_zhang', 'parkinson'\n",
    "            neutral_zone: Se True, cria zona morta entre thresholds\n",
    "        \"\"\"\n",
    "        self.horizon_bars = horizon_bars\n",
    "        self.k = k\n",
    "        self.vol_estimator = vol_estimator\n",
    "        self.neutral_zone = neutral_zone\n",
    "        self.volatility_estimators = VolatilityEstimators()\n",
    "        \n",
    "        # Mapeamento de horizontes em minutos para bars de 15m\n",
    "        # Calcular horizonte de funding dinamicamente\n",
    "        funding_period_minutes = getattr(self, 'funding_period_minutes', 480)\n",
    "        funding_horizon_bars = funding_period_minutes // 15  # converter para barras de 15min\n",
    "        \n",
    "        self.horizon_map = {\n",
    "            '15m': 1,   # 15 minutos = 1 bar\n",
    "            '30m': 2,   # 30 minutos = 2 bars\n",
    "            '60m': 4,   # 60 minutos = 4 bars\n",
    "            '120m': 8,  # 120 minutos = 8 bars\n",
    "            '240m': 16, # 240 minutos = 16 bars\n",
    "            f'{funding_period_minutes}m': funding_horizon_bars  # funding cycle dinâmico\n",
    "        }\n",
    "    \n",
    "    def calculate_volatility(self, df: pd.DataFrame, window: int = 20) -> pd.Series:\n",
    "        \"\"\"Calcula volatilidade usando estimador selecionado\"\"\"\n",
    "        estimator_map = {\n",
    "            'atr': self.volatility_estimators.atr,\n",
    "            'garman_klass': self.volatility_estimators.garman_klass,\n",
    "            'yang_zhang': self.volatility_estimators.yang_zhang,\n",
    "            'parkinson': self.volatility_estimators.parkinson,\n",
    "            'realized': self.volatility_estimators.realized_volatility\n",
    "        }\n",
    "        \n",
    "        if self.vol_estimator not in estimator_map:\n",
    "            raise ValueError(f\"Estimador {self.vol_estimator} não suportado\")\n",
    "        \n",
    "        return estimator_map[self.vol_estimator](df, window)\n",
    "    \n",
    "    def calculate_adaptive_threshold(self, df: pd.DataFrame, \n",
    "                                    window: int = 20) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calcula threshold adaptativo baseado em volatilidade\n",
    "        \n",
    "        Returns:\n",
    "            Series com threshold adaptativo para cada barra\n",
    "        \"\"\"\n",
    "        volatility = self.calculate_volatility(df, window)\n",
    "        \n",
    "        # Ajustar threshold baseado na volatilidade e horizonte\n",
    "        # Horizonte maior = threshold maior\n",
    "        horizon_adjustment = np.sqrt(self.horizon_bars)\n",
    "        \n",
    "        threshold = self.k * volatility * horizon_adjustment\n",
    "        \n",
    "        # Aplicar limite mínimo e máximo\n",
    "        threshold = threshold.clip(lower=0.001, upper=0.10)\n",
    "        \n",
    "        return threshold\n",
    "    \n",
    "    def create_labels(self, df: pd.DataFrame, window: int = 20) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Cria labels baseados em threshold adaptativo\n",
    "        \n",
    "        Returns:\n",
    "            Series com labels: 1 (long), 0 (neutral), -1 (short)\n",
    "        \"\"\"\n",
    "        # Calcular retorno futuro\n",
    "        future_return = (\n",
    "            df['close'].shift(-self.horizon_bars) / df['close'] - 1\n",
    "        )\n",
    "        \n",
    "        # Calcular threshold adaptativo\n",
    "        threshold = self.calculate_adaptive_threshold(df, window)\n",
    "        \n",
    "        # Criar labels\n",
    "        labels = pd.Series(index=df.index, dtype=float)\n",
    "        \n",
    "        if self.neutral_zone:\n",
    "            # Com zona neutra: -1, 0, 1\n",
    "            labels[future_return > threshold] = 1  # Long\n",
    "            labels[future_return < -threshold] = -1  # Short  \n",
    "            labels[(future_return >= -threshold) & (future_return <= threshold)] = 0  # Neutral\n",
    "        else:\n",
    "            # Sem zona neutra: -1, 1\n",
    "            labels[future_return > 0] = 1  # Long\n",
    "            labels[future_return <= 0] = -1  # Short\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def get_label_distribution(self, labels: pd.Series) -> Dict:\n",
    "        \"\"\"Retorna distribuição dos labels\"\"\"\n",
    "        counts = labels.value_counts()\n",
    "        proportions = labels.value_counts(normalize=True)\n",
    "        \n",
    "        return {\n",
    "            'counts': counts.to_dict(),\n",
    "            'proportions': proportions.to_dict(),\n",
    "            'total': len(labels.dropna()),\n",
    "            'balance_ratio': counts.min() / counts.max() if len(counts) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def optimize_k_for_horizon(self, df: pd.DataFrame, X: pd.DataFrame,\n",
    "                               horizon: str, cv_splits: int = 3,\n",
    "                               metric: str = 'f1',\n",
    "                               k_range: Tuple[float, float] = (0.5, 2.0)) -> float:\n",
    "        \"\"\"\n",
    "        Otimiza o multiplicador k para um horizonte específico\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame com OHLC\n",
    "            X: Features\n",
    "            horizon: Horizonte alvo ('15m', '30m', etc)\n",
    "            cv_splits: Número de splits para validação\n",
    "            metric: Métrica para otimização ('f1', 'pr_auc')\n",
    "            k_range: Range de valores de k para testar\n",
    "            \n",
    "        Returns:\n",
    "            float: k ótimo para o horizonte\n",
    "        \"\"\"\n",
    "        # Imports já feitos no início do arquivo, não precisam ser repetidos\n",
    "        \n",
    "        # Configurar horizonte\n",
    "        self.horizon_bars = self.horizon_map[horizon]\n",
    "        \n",
    "        best_k = self.k\n",
    "        best_score = -np.inf\n",
    "        \n",
    "        # Testar diferentes valores de k\n",
    "        k_values = np.linspace(k_range[0], k_range[1], 20)\n",
    "        \n",
    "        for k in k_values:\n",
    "            self.k = k\n",
    "            \n",
    "            # Criar labels com k atual\n",
    "            labels = self.create_labels(df)\n",
    "            \n",
    "            # Remover NaN\n",
    "            mask = ~(labels.isna() | X.isna().any(axis=1))\n",
    "            X_clean = X[mask]\n",
    "            y_clean = labels[mask]\n",
    "            \n",
    "            # Converter para binário se necessário\n",
    "            if metric in ['f1', 'pr_auc']:\n",
    "                y_clean = (y_clean > 0).astype(int)\n",
    "            \n",
    "            # Validação cruzada temporal\n",
    "            tscv = TimeSeriesSplit(n_splits=cv_splits)\n",
    "            scores = []\n",
    "            \n",
    "            for train_idx, val_idx in tscv.split(X_clean):\n",
    "                X_train, X_val = X_clean.iloc[train_idx], X_clean.iloc[val_idx]\n",
    "                y_train, y_val = y_clean.iloc[train_idx], y_clean.iloc[val_idx]\n",
    "                \n",
    "                # Modelo simples para avaliação rápida\n",
    "                model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                if metric == 'f1':\n",
    "                    y_pred = model.predict(X_val)\n",
    "                    score = f1_score(y_val, y_pred, average='weighted')\n",
    "                elif metric == 'pr_auc':\n",
    "                    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "                    score = average_precision_score(y_val, y_proba)\n",
    "                else:\n",
    "                    raise ValueError(f\"Métrica {metric} não suportada\")\n",
    "                \n",
    "                scores.append(score)\n",
    "            \n",
    "            avg_score = np.mean(scores)\n",
    "            \n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_k = k\n",
    "            \n",
    "            print(f\"k={k:.2f}: {metric}={avg_score:.4f}\")\n",
    "        \n",
    "        print(f\"✅ k ótimo para {horizon}: {best_k:.3f}\")\n",
    "        \n",
    "        return best_k\n",
    "    \n",
    "    def optimize_k_multi_horizon(self, df: pd.DataFrame, X: pd.DataFrame,\n",
    "                                 horizons: List[str] = None,\n",
    "                                 cv_splits: int = 3,\n",
    "                                 metric: str = 'pr_auc') -> Dict:\n",
    "        \"\"\"\n",
    "        Otimiza k para múltiplos horizontes simultaneamente\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame com OHLC\n",
    "            X: Features\n",
    "            horizons: Lista de horizontes para otimizar\n",
    "            cv_splits: Número de splits para CV\n",
    "            metric: Métrica para otimização ('f1', 'pr_auc')\n",
    "            \n",
    "        Returns:\n",
    "            Dict com k ótimo para cada horizonte\n",
    "        \"\"\"\n",
    "        if horizons is None:\n",
    "            horizons = ['15m', '30m', '60m', '120m']\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for horizon in horizons:\n",
    "            print(f\"\\nOtimizando k para horizonte {horizon}...\")\n",
    "            optimal_k = self.optimize_k_for_horizon(\n",
    "                df, X, horizon, cv_splits, metric\n",
    "            )\n",
    "            results[horizon] = optimal_k\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def optimize_k(self, df: pd.DataFrame, X: pd.DataFrame, \n",
    "                   cv_splits: int = 5, metric: str = 'f1') -> float:\n",
    "        \"\"\"\n",
    "        Otimiza o multiplicador k usando validação cruzada temporal\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame com OHLC\n",
    "            X: Features para treino\n",
    "            cv_splits: Número de splits temporais\n",
    "            metric: 'f1' ou 'balanced_accuracy'\n",
    "            \n",
    "        Returns:\n",
    "            float: k ótimo\n",
    "        \"\"\"\n",
    "        # Imports já feitos no início do arquivo, não precisam ser repetidos\n",
    "        \n",
    "        best_k = self.k\n",
    "        best_score = -np.inf\n",
    "        \n",
    "        # Range de k para testar\n",
    "        k_values = np.linspace(0.5, 2.0, 20)\n",
    "        \n",
    "        for k in k_values:\n",
    "            self.k = k\n",
    "            \n",
    "            # Criar labels com k atual\n",
    "            labels = self.create_labels(df)\n",
    "            \n",
    "            # Remover NaN\n",
    "            mask = ~(labels.isna() | X.isna().any(axis=1))\n",
    "            X_clean = X[mask]\n",
    "            y_clean = labels[mask]\n",
    "            \n",
    "            # Converter para binário (up/down)\n",
    "            y_binary = (y_clean > 0).astype(int)\n",
    "            \n",
    "            # Time Series CV\n",
    "            tscv = TimeSeriesSplit(n_splits=cv_splits)\n",
    "            scores = []\n",
    "            \n",
    "            for train_idx, val_idx in tscv.split(X_clean):\n",
    "                X_train, X_val = X_clean.iloc[train_idx], X_clean.iloc[val_idx]\n",
    "                y_train, y_val = y_binary.iloc[train_idx], y_binary.iloc[val_idx]\n",
    "                \n",
    "                # Modelo simples para teste rápido\n",
    "                clf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_val)\n",
    "                \n",
    "                if metric == 'f1':\n",
    "                    score = f1_score(y_val, y_pred, average='weighted')\n",
    "                else:\n",
    "                    score = balanced_accuracy_score(y_val, y_pred)\n",
    "                \n",
    "                scores.append(score)\n",
    "            \n",
    "            avg_score = np.mean(scores)\n",
    "            \n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_k = k\n",
    "            \n",
    "            print(f\"k={k:.2f}: {metric}={avg_score:.4f}\")\n",
    "        \n",
    "        self.k = best_k\n",
    "        return best_k\n",
    "\n",
    "print(\"✅ Classe AdaptiveLabeler definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37658733",
   "metadata": {},
   "source": [
    "## 6. Features para Mercado Cripto 24/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a940e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Classe Crypto24x7Features definida\n"
     ]
    }
   ],
   "source": [
    "# Resolver dinâmico de funding period\n",
    "def resolve_funding_minutes(symbol: str, timestamp: pd.Timestamp = None) -> int:\n",
    "    \"\"\"\n",
    "    Resolve o período de funding dinamicamente baseado no símbolo e data.\n",
    "    \n",
    "    Regras (fonte: Binance Support):\n",
    "    - Padrão: 480 min (8 horas) para maioria dos contratos perpétuos\n",
    "    - Condicional: 60 min (1 hora) quando funding rate atinge cap/floor\n",
    "    - Especial: Alguns contratos podem ter 240 min (4 horas)\n",
    "    \n",
    "    Args:\n",
    "        symbol: Símbolo do contrato (ex: BTCUSDT)\n",
    "        timestamp: Data/hora para verificar regras específicas do período\n",
    "        \n",
    "    Returns:\n",
    "        Período de funding em minutos\n",
    "    \"\"\"\n",
    "    # Dicionário base de funding por símbolo\n",
    "    # Fonte: https://www.binance.com/en/support/faq/detail/360033525031\n",
    "    FUNDING_PERIODS = {\n",
    "        # Majors - 8 horas padrão\n",
    "        \"BTCUSDT\": 480,\n",
    "        \"ETHUSDT\": 480,\n",
    "        \"BNBUSDT\": 480,\n",
    "        \"XRPUSDT\": 480,\n",
    "        \"ADAUSDT\": 480,\n",
    "        \"SOLUSDT\": 480,\n",
    "        \"DOTUSDT\": 480,\n",
    "        \"DOGEUSDT\": 480,\n",
    "        \n",
    "        # Contratos com período especial (exemplos)\n",
    "        # Adicionar conforme documentação da exchange\n",
    "    }\n",
    "    \n",
    "    # Obter período base do símbolo\n",
    "    base_period = FUNDING_PERIODS.get(symbol, 480)  # Default 8h\n",
    "    \n",
    "    # TODO: Implementar lógica condicional\n",
    "    # Se funding rate atingir cap/floor, pode mudar para 1h temporariamente\n",
    "    # Isso requer acesso ao funding rate atual da exchange\n",
    "    \n",
    "    # Log da decisão\n",
    "    if timestamp:\n",
    "        print(f\"📊 Funding period para {symbol} em {timestamp}: {base_period} min ({base_period/60:.1f}h)\")\n",
    "    \n",
    "    return base_period\n",
    "\n",
    "class Crypto24x7Features:\n",
    "    \"\"\"\n",
    "    Features específicas para mercado cripto 24/7\n",
    "    Inclui calendário, sessões regionais e funding\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_calendar_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Cria features de calendário 24/7\n",
    "        \n",
    "        Crypto não tem fechamento, mas tem padrões:\n",
    "        - Horários de maior volume (overlaps de mercados)\n",
    "        - Dias da semana\n",
    "        - Fim de mês (rebalanceamento de portfolios)\n",
    "        \"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "        \n",
    "        # Extrair componentes temporais\n",
    "        features['hour'] = df.index.hour\n",
    "        features['day_of_week'] = df.index.dayofweek\n",
    "        features['day_of_month'] = df.index.day\n",
    "        features['week_of_year'] = df.index.isocalendar().week\n",
    "        features['month'] = df.index.month\n",
    "        features['quarter'] = df.index.quarter\n",
    "        \n",
    "        # Features cíclicas (encoding circular)\n",
    "        features['hour_sin'] = np.sin(2 * np.pi * features['hour'] / 24)\n",
    "        features['hour_cos'] = np.cos(2 * np.pi * features['hour'] / 24)\n",
    "        features['dow_sin'] = np.sin(2 * np.pi * features['day_of_week'] / 7)\n",
    "        features['dow_cos'] = np.cos(2 * np.pi * features['day_of_week'] / 7)\n",
    "        features['month_sin'] = np.sin(2 * np.pi * features['month'] / 12)\n",
    "        features['month_cos'] = np.cos(2 * np.pi * features['month'] / 12)\n",
    "        \n",
    "        # Períodos especiais\n",
    "        features['is_weekend'] = (features['day_of_week'] >= 5).astype(int)\n",
    "        features['is_month_end'] = (df.index.day >= 28).astype(int)\n",
    "        features['is_quarter_end'] = ((features['month'] % 3 == 0) & \n",
    "                                      (features['is_month_end'] == 1)).astype(int)\n",
    "        \n",
    "        # Horário combinado (0-167 para hora da semana)\n",
    "        features['hour_of_week'] = features['day_of_week'] * 24 + features['hour']\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_session_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Identifica sessões de trading regionais\n",
    "        \n",
    "        Principais sessões (UTC):\n",
    "        - Asia: 00:00 - 09:00\n",
    "        - Europe: 07:00 - 16:00  \n",
    "        - Americas: 13:00 - 22:00\n",
    "        \"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "        hour = df.index.hour\n",
    "        \n",
    "        # Sessões principais\n",
    "        features['session_asia'] = ((hour >= 0) & (hour < 9)).astype(int)\n",
    "        features['session_europe'] = ((hour >= 7) & (hour < 16)).astype(int)\n",
    "        features['session_americas'] = ((hour >= 13) & (hour < 22)).astype(int)\n",
    "        \n",
    "        # Overlaps (maior volume/volatilidade)\n",
    "        features['overlap_asia_europe'] = ((hour >= 7) & (hour < 9)).astype(int)\n",
    "        features['overlap_europe_americas'] = ((hour >= 13) & (hour < 16)).astype(int)\n",
    "        \n",
    "        # Contagem de sessões ativas\n",
    "        features['active_sessions'] = (\n",
    "            features['session_asia'] + \n",
    "            features['session_europe'] + \n",
    "            features['session_americas']\n",
    "        )\n",
    "        \n",
    "        # Período de baixa atividade\n",
    "        features['low_activity'] = (features['active_sessions'] == 0).astype(int)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_funding_features(df: pd.DataFrame, \n",
    "                               features: pd.DataFrame = None,\n",
    "                               funding_period_minutes: int = 480) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Features relacionadas ao funding rate (perpetual futures)\n",
    "        \n",
    "        Default é 480 minutos (8 horas) - padrão da maioria dos contratos perpetuais\n",
    "        Alguns contratos específicos usam 60 minutos (1 hora) - ajustar por símbolo\n",
    "        \"\"\"\n",
    "        if features is None:\n",
    "            features = pd.DataFrame(index=df.index)\n",
    "        else:\n",
    "            features = features.copy()\n",
    "        \n",
    "        # Converter período de funding para barras (15min cada)\n",
    "        funding_period_bars = funding_period_minutes // 15  # minutos / 15 = barras\n",
    "        \n",
    "        # Identificar proximidade ao funding\n",
    "        hour = df.index.hour\n",
    "        minute = df.index.minute\n",
    "        \n",
    "        # Minutos até próximo funding\n",
    "        minutes_in_day = hour * 60 + minute\n",
    "        \n",
    "        # Gerar funding times dinamicamente baseado no período\n",
    "        funding_times = list(range(0, 1440, funding_period_minutes))\n",
    "        \n",
    "        # Calcular minutos até próximo funding\n",
    "        features['minutes_to_funding'] = [\n",
    "            min(((ft - m) % 1440) for ft in funding_times) \n",
    "            for m in minutes_in_day\n",
    "        ]\n",
    "        \n",
    "        features['bars_to_funding'] = features['minutes_to_funding'] / 15\n",
    "        \n",
    "        # Proximidade ao funding (decai exponencialmente)\n",
    "        features['funding_proximity'] = np.exp(-features['bars_to_funding'] / 10)\n",
    "        \n",
    "        # É hora de funding?\n",
    "        features['is_funding_time'] = (features['minutes_to_funding'] == 0).astype(int)\n",
    "        \n",
    "        # Janela pré-funding (proporção do período - 12.5% antes do funding)\n",
    "        pre_funding_minutes = min(60, funding_period_minutes // 8)  # Máximo 1 hora, ou 1/8 do período\n",
    "        features['pre_funding_window'] = (features['minutes_to_funding'] <= pre_funding_minutes).astype(int)\n",
    "        \n",
    "        # Ciclo de funding (qual período estamos)\n",
    "        features['funding_cycle'] = (minutes_in_day // funding_period_minutes).astype(int)\n",
    "        \n",
    "        # Features cíclicas para funding\n",
    "        features['funding_cycle_sin'] = np.sin(2 * np.pi * features['bars_to_funding'] / funding_period_bars)\n",
    "        features['funding_cycle_cos'] = np.cos(2 * np.pi * features['bars_to_funding'] / funding_period_bars)\n",
    "        \n",
    "        return features\n",
    "\n",
    "print(\"✅ Classe Crypto24x7Features definida\")# %% [markdown]\n",
    "# ## 7. Pipeline Multi-Horizonte de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d802a86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Função run_multi_horizon_pipeline definida\n"
     ]
    }
   ],
   "source": [
    "def run_multi_horizon_pipeline(df: pd.DataFrame, \n",
    "                              features: pd.DataFrame,\n",
    "                              horizons: List[str] = ['15m', '30m', '60m', '120m'],\n",
    "                              test_size: float = 0.2,\n",
    "                              val_size: float = 0.2,\n",
    "                              n_trials: int = 20,  # Reduzido para otimização de memória\n",
    "                              k_range: Tuple[float, float] = (0.5, 2.0)) -> Dict:\n",
    "    \"\"\"\n",
    "    Pipeline completo para treinar e avaliar modelos em múltiplos horizontes\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame com OHLC\n",
    "        features: Features preparadas\n",
    "        horizons: Lista de horizontes para avaliar\n",
    "        test_size: Proporção para teste\n",
    "        val_size: Proporção para validação  \n",
    "        n_trials: Número de trials Optuna\n",
    "        k_range: Range para otimização do k\n",
    "        \n",
    "    Returns:\n",
    "        Dict com resultados para cada horizonte\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"🚀 INICIANDO PIPELINE MULTI-HORIZONTE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Verificar disponibilidade de bibliotecas\n",
    "    if not XGB_AVAILABLE:\n",
    "        raise ImportError(\"XGBoost não está disponível\")\n",
    "    \n",
    "    # Informar sobre status das bibliotecas opcionais\n",
    "    if not OPTUNA_AVAILABLE:\n",
    "        print(\"⚠️ Optuna não disponível - usando hiperparâmetros padrão\")\n",
    "    elif not OPTUNA_XGBOOST_INTEGRATION:\n",
    "        print(\"⚠️ Optuna XGBoost integration não disponível - usando otimização básica\")\n",
    "    \n",
    "    if not MLFLOW_AVAILABLE:\n",
    "        print(\"⚠️ MLflow não disponível - resultados não serão tracked\")\n",
    "    \n",
    "    if not SHAP_AVAILABLE:\n",
    "        print(\"⚠️ SHAP não disponível - interpretabilidade limitada\")\n",
    "    \n",
    "    # Estrutura para armazenar resultados\n",
    "    results = {}\n",
    "    \n",
    "    # Configurar MLflow\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        import mlflow\n",
    "        experiment_name = f\"multi_horizon_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Split temporal dos dados\n",
    "    n_samples = len(df)\n",
    "    test_start = int(n_samples * (1 - test_size))\n",
    "    val_start = int(n_samples * (1 - test_size - val_size))\n",
    "    \n",
    "    train_idx = slice(0, val_start)\n",
    "    val_idx = slice(val_start, test_start)\n",
    "    test_idx = slice(test_start, n_samples)\n",
    "    \n",
    "    print(f\"\\n📊 Split dos dados:\")\n",
    "    print(f\"  Train: {val_start} samples ({val_start/n_samples:.1%})\")\n",
    "    print(f\"  Val:   {test_start - val_start} samples ({val_size:.1%})\")\n",
    "    print(f\"  Test:  {n_samples - test_start} samples ({test_size:.1%})\")\n",
    "    \n",
    "    # Adicionar features de funding cycle parametrizado por símbolo\n",
    "    crypto_features = Crypto24x7Features()\n",
    "    \n",
    "    # Resolver período de funding dinamicamente\n",
    "    symbol = config.symbol if 'config' in locals() else \"BTCUSDT\"\n",
    "    last_timestamp = df.index[-1] if not df.empty else None\n",
    "    funding_period_minutes = resolve_funding_minutes(symbol, last_timestamp)\n",
    "    \n",
    "    # Log adicional se MLflow disponível  \n",
    "    if MLFLOW_AVAILABLE:\n",
    "        import mlflow\n",
    "        mlflow.log_param(\"funding_period_minutes\", funding_period_minutes)\n",
    "        mlflow.log_param(\"funding_symbol\", symbol)\n",
    "    \n",
    "    features_with_funding = crypto_features.create_funding_features(\n",
    "        df, features, funding_period_minutes=funding_period_minutes\n",
    "    )\n",
    "    \n",
    "    # Processar cada horizonte\n",
    "    for horizon in horizons:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"⏱️ Processando horizonte: {horizon}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        run_context = None\n",
    "        if MLFLOW_AVAILABLE:\n",
    "            import mlflow\n",
    "            try:\n",
    "                run_context = mlflow.start_run(run_name=f\"horizon_{horizon}\", nested=True)\n",
    "            except Exception:\n",
    "                # Se der erro com nested, tentar sem ou finalizar run anterior\n",
    "                try:\n",
    "                    mlflow.end_run()\n",
    "                    run_context = mlflow.start_run(run_name=f\"horizon_{horizon}\")\n",
    "                except Exception:\n",
    "                    print(\"⚠️ Erro ao inicializar MLflow run - continuando sem tracking\")\n",
    "                    run_context = None\n",
    "        \n",
    "        try:\n",
    "            # Log do horizonte\n",
    "            if MLFLOW_AVAILABLE:\n",
    "                import mlflow\n",
    "                mlflow.log_param(\"horizon\", horizon)\n",
    "                mlflow.log_param(\"n_trials\", n_trials)\n",
    "                mlflow.log_param(\"k_range\", k_range)\n",
    "            \n",
    "            # 1. Criar labels para este horizonte\n",
    "            labeler = AdaptiveLabeler(vol_estimator='yang_zhang')\n",
    "            horizon_bars = labeler.horizon_map[horizon]\n",
    "            \n",
    "            # Otimizar k para este horizonte\n",
    "            print(f\"\\n🔍 Otimizando k para horizonte {horizon}...\")\n",
    "            optimal_k = labeler.optimize_k_for_horizon(\n",
    "                df[train_idx], \n",
    "                features_with_funding[train_idx],\n",
    "                horizon=horizon,\n",
    "                cv_splits=3,\n",
    "                metric='pr_auc'\n",
    "            )\n",
    "            \n",
    "            if MLFLOW_AVAILABLE:\n",
    "                import mlflow\n",
    "                mlflow.log_metric(f\"optimal_k_{horizon}\", optimal_k)\n",
    "            \n",
    "            # Criar labels com k otimizado\n",
    "            labeler.k = optimal_k\n",
    "            labeler.horizon_bars = horizon_bars\n",
    "            labels = labeler.create_labels(df)\n",
    "            \n",
    "            # 2. Preparar dados\n",
    "            X_train = features_with_funding[train_idx]\n",
    "            y_train = labels[train_idx]\n",
    "            X_val = features_with_funding[val_idx]\n",
    "            y_val = labels[val_idx]\n",
    "            X_test = features_with_funding[test_idx]\n",
    "            y_test = labels[test_idx]\n",
    "            \n",
    "            # Remover NaN\n",
    "            mask_train = ~(X_train.isna().any(axis=1) | y_train.isna())\n",
    "            mask_val = ~(X_val.isna().any(axis=1) | y_val.isna())\n",
    "            mask_test = ~(X_test.isna().any(axis=1) | y_test.isna())\n",
    "            \n",
    "            X_train = X_train[mask_train]\n",
    "            y_train = y_train[mask_train]\n",
    "            X_val = X_val[mask_val]\n",
    "            y_val = y_val[mask_val]\n",
    "            X_test = X_test[mask_test]\n",
    "            y_test = y_test[mask_test]\n",
    "            \n",
    "            # Converter labels para binário (1: up, 0: down/neutral)\n",
    "            y_train_binary = (y_train > 0).astype(int)\n",
    "            y_val_binary = (y_val > 0).astype(int)\n",
    "            y_test_binary = (y_test > 0).astype(int)\n",
    "            \n",
    "            # Log distribuição das classes\n",
    "            train_pos_pct = y_train_binary.mean()\n",
    "            val_pos_pct = y_val_binary.mean()\n",
    "            test_pos_pct = y_test_binary.mean()\n",
    "            \n",
    "            print(f\"\\n📈 Distribuição das classes:\")\n",
    "            print(f\"  Train: {train_pos_pct:.2%} positivos\")\n",
    "            print(f\"  Val:   {val_pos_pct:.2%} positivos\")\n",
    "            print(f\"  Test:  {test_pos_pct:.2%} positivos\")\n",
    "            \n",
    "            if MLFLOW_AVAILABLE:\n",
    "                mlflow.log_metric(\"train_positive_pct\", train_pos_pct)\n",
    "                mlflow.log_metric(\"val_positive_pct\", val_pos_pct)\n",
    "            \n",
    "            # 3. XGBoost não precisa de normalização (trees são invariantes à escala)\n",
    "            # Manter dados originais para melhor interpretabilidade\n",
    "            X_train_scaled = X_train\n",
    "            X_val_scaled = X_val\n",
    "            X_test_scaled = X_test\n",
    "            scaler = None  # XGBoost não precisa\n",
    "            \n",
    "            # 4. Otimização com Optuna\n",
    "            print(f\"\\n🎯 Otimizando XGBoost com Optuna...\")\n",
    "            \n",
    "            def objective(trial):\n",
    "                params = {\n",
    "                    'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                    'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                    'gamma': trial.suggest_float('gamma', 0.0, 0.5),\n",
    "                    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "                    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "                    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                    'scale_pos_weight': ((1 - train_pos_pct) / train_pos_pct) if train_pos_pct > 0 else 1.0,\n",
    "                    'objective': 'binary:logistic',\n",
    "                    'eval_metric': 'aucpr',\n",
    "                    'tree_method': 'hist',\n",
    "                    'random_state': 42\n",
    "                }\n",
    "                \n",
    "                # Treinar com early stopping e pruning\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                \n",
    "                # Usar callback apropriado baseado na disponibilidade\n",
    "                callbacks = []\n",
    "                if OPTUNA_AVAILABLE:\n",
    "                    callbacks.append(create_xgb_pruning_callback(trial, \"validation_0-aucpr\"))\n",
    "                \n",
    "                model.fit(\n",
    "                    X_train_scaled, y_train_binary,\n",
    "                    eval_set=[(X_val_scaled, y_val_binary)],\n",
    "                    verbose=False,\n",
    "                    early_stopping_rounds=200,\n",
    "                    callbacks=callbacks if callbacks else None\n",
    "                )\n",
    "                \n",
    "                # Salvar melhor iteração no trial\n",
    "                if hasattr(model, 'best_iteration'):\n",
    "                    trial.set_user_attr('best_iteration', model.best_iteration)\n",
    "                \n",
    "                # Avaliar com PR-AUC\n",
    "                y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "                pr_auc = average_precision_score(y_val_binary, y_pred_proba)\n",
    "                \n",
    "                return pr_auc\n",
    "            \n",
    "            # Executar otimização\n",
    "            if OPTUNA_AVAILABLE:\n",
    "                study = safe_optuna_study(\n",
    "                    direction='maximize',\n",
    "                    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "                    pruner=optuna.pruners.MedianPruner()\n",
    "                )\n",
    "                \n",
    "                study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "                \n",
    "                # Melhores parâmetros\n",
    "                best_params = study.best_params\n",
    "                best_score = study.best_value\n",
    "            else:\n",
    "                # Fallback: usar hiperparâmetros padrão otimizados\n",
    "                print(\"⚠️ Usando hiperparâmetros padrão (Optuna não disponível)\")\n",
    "                best_params = {\n",
    "                    'max_depth': 6,\n",
    "                    'learning_rate': 0.05,\n",
    "                    'n_estimators': 200,\n",
    "                    'subsample': 0.8,\n",
    "                    'colsample_bytree': 0.8,\n",
    "                    'gamma': 0.1,\n",
    "                    'reg_alpha': 0.1,\n",
    "                    'reg_lambda': 1.0,\n",
    "                    'min_child_weight': 1,\n",
    "                    'scale_pos_weight': ((1 - train_pos_pct) / train_pos_pct) if train_pos_pct > 0 else 1.0,\n",
    "                    'objective': 'binary:logistic',\n",
    "                    'eval_metric': 'aucpr',\n",
    "                    'tree_method': 'hist',\n",
    "                    'random_state': 42\n",
    "                }\n",
    "                \n",
    "                # Avaliar hiperparâmetros padrão\n",
    "                temp_model = xgb.XGBClassifier(**best_params)\n",
    "                temp_model.fit(X_train_scaled, y_train_binary, eval_set=[(X_val_scaled, y_val_binary)], verbose=False, early_stopping_rounds=200)\n",
    "                y_pred_proba = temp_model.predict_proba(X_val_scaled)[:, 1]\n",
    "                best_score = average_precision_score(y_val_binary, y_pred_proba)\n",
    "            \n",
    "            # Recuperar melhor iteração se disponível (só quando Optuna usado)\n",
    "            if OPTUNA_AVAILABLE and 'study' in locals():\n",
    "                best_iteration = study.best_trial.user_attrs.get('best_iteration')\n",
    "                if best_iteration is not None:\n",
    "                    best_params['n_estimators'] = int(best_iteration)\n",
    "                    print(f\"📊 Usando melhor iteração do early stopping: {best_iteration}\")\n",
    "            \n",
    "            best_params.update({\n",
    "                'scale_pos_weight': ((1 - train_pos_pct) / train_pos_pct) if train_pos_pct > 0 else 1.0,\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'aucpr',\n",
    "                'tree_method': 'hist',\n",
    "                'random_state': 42\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n✅ Melhor PR-AUC em validação: {best_score:.4f}\")\n",
    "            \n",
    "            if MLFLOW_AVAILABLE:\n",
    "                mlflow.log_metric(f\"best_pr_auc_val_{horizon}\", best_score)\n",
    "                mlflow.log_params({f\"xgb_{k}_{horizon}\": v for k, v in best_params.items()})\n",
    "            \n",
    "            # 5. Treinar modelo final\n",
    "            print(f\"\\n🏋️ Treinando modelo final...\")\n",
    "            final_model = xgb.XGBClassifier(**best_params)\n",
    "            final_model.fit(\n",
    "                X_train_scaled, y_train_binary,\n",
    "                eval_set=[(X_val_scaled, y_val_binary)],\n",
    "                verbose=False,\n",
    "                early_stopping_rounds=200  # Manter early stopping no modelo final\n",
    "            )\n",
    "            \n",
    "            # 6. Calibração de probabilidades\n",
    "            print(f\"\\n📐 Calibrando probabilidades...\")\n",
    "            calibrator = CalibratedClassifierCV(\n",
    "                final_model, \n",
    "                method='isotonic',\n",
    "                cv='prefit'\n",
    "            )\n",
    "            calibrator.fit(X_val, y_val_binary)  # Usar dados originais\n",
    "            \n",
    "            # 7. Otimizar threshold no VALIDATION (não no teste!)\n",
    "            print(f\"\\n🔍 Otimizando threshold no conjunto de validação...\")\n",
    "            \n",
    "            # Predições calibradas no validation para escolher threshold\n",
    "            y_val_pred_cal = calibrator.predict_proba(X_val)[:, 1]\n",
    "            \n",
    "            # Otimizar threshold baseado em F1 no VALIDATION\n",
    "            precision, recall, thresholds = precision_recall_curve(\n",
    "                y_val_binary, y_val_pred_cal\n",
    "            )\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "            best_threshold_idx = np.argmax(f1_scores)\n",
    "            best_threshold = thresholds[best_threshold_idx] if best_threshold_idx < len(thresholds) else 0.5\n",
    "            \n",
    "            print(f\"  Threshold ótimo (do validation): {best_threshold:.4f}\")\n",
    "            \n",
    "            # 8. Avaliação em teste com threshold fixo\n",
    "            print(f\"\\n📊 Avaliando em conjunto de teste com threshold fixo...\")\n",
    "            \n",
    "            # Predições não calibradas\n",
    "            y_test_pred_raw = final_model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Predições calibradas\n",
    "            y_test_pred_cal = calibrator.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Aplicar threshold\n",
    "            y_test_pred_binary = (y_test_pred_cal >= best_threshold).astype(int)\n",
    "            \n",
    "            # Métricas finais\n",
    "            test_pr_auc = average_precision_score(y_test_binary, y_test_pred_cal)\n",
    "            test_f1 = f1_score(y_test_binary, y_test_pred_binary)\n",
    "            test_mcc = matthews_corrcoef(y_test_binary, y_test_pred_binary)\n",
    "            \n",
    "            # Matriz de confusão (com labels explícitos para evitar erros)\n",
    "            cm = confusion_matrix(y_test_binary, y_test_pred_binary, labels=[0, 1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            \n",
    "            # Métricas adicionais\n",
    "            precision_score_val = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall_score_val = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            \n",
    "            print(f\"\\n📈 Métricas em teste para {horizon}:\")\n",
    "            print(f\"  PR-AUC:      {test_pr_auc:.4f}\")\n",
    "            print(f\"  F1 Score:    {test_f1:.4f}\")\n",
    "            print(f\"  MCC:         {test_mcc:.4f}\")\n",
    "            print(f\"  Precision:   {precision_score_val:.4f}\")\n",
    "            print(f\"  Recall:      {recall_score_val:.4f}\")\n",
    "            print(f\"  Specificity: {specificity:.4f}\")\n",
    "            print(f\"  Threshold:   {best_threshold:.4f}\")\n",
    "            \n",
    "            # Log métricas no MLflow\n",
    "            if MLFLOW_AVAILABLE:\n",
    "                import mlflow\n",
    "                mlflow.log_metrics({\n",
    "                    f\"test_pr_auc_{horizon}\": test_pr_auc,\n",
    "                    f\"test_f1_{horizon}\": test_f1,\n",
    "                    f\"test_mcc_{horizon}\": test_mcc,\n",
    "                    f\"test_precision_{horizon}\": precision_score_val,\n",
    "                    f\"test_recall_{horizon}\": recall_score_val,\n",
    "                    f\"test_specificity_{horizon}\": specificity,\n",
    "                    f\"best_threshold_{horizon}\": best_threshold\n",
    "                })\n",
    "            \n",
    "            # 8. Análise de importância de features\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': X_train.columns,\n",
    "                'importance': final_model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(f\"\\n🔝 Top 10 features mais importantes:\")\n",
    "            for idx, row in feature_importance.head(10).iterrows():\n",
    "                print(f\"  {row['feature']:30s}: {row['importance']:.4f}\")\n",
    "            \n",
    "            # Salvar resultados (incluindo índices para alinhamento no backtest)\n",
    "            results[horizon] = {\n",
    "                'model': final_model,\n",
    "                'calibrator': calibrator,\n",
    "                'scaler': scaler,\n",
    "                'labeler': labeler,\n",
    "                'threshold': best_threshold,\n",
    "                'metrics': {\n",
    "                    'pr_auc': test_pr_auc,\n",
    "                    'f1': test_f1,\n",
    "                    'mcc': test_mcc,\n",
    "                    'precision': precision_score_val,\n",
    "                    'recall': recall_score_val,\n",
    "                    'specificity': specificity\n",
    "                },\n",
    "                'confusion_matrix': cm,\n",
    "                'feature_importance': feature_importance,\n",
    "                'predictions': {\n",
    "                    'raw': y_test_pred_raw,\n",
    "                    'calibrated': y_test_pred_cal,\n",
    "                    'binary': y_test_pred_binary\n",
    "                },\n",
    "                'labels': y_test_binary,\n",
    "                'optimal_k': optimal_k,\n",
    "                'test_indices': X_test.index  # Salvar índices para backtest\n",
    "            }\n",
    "            \n",
    "            # Limpeza de memória após cada horizonte\n",
    "            del X_train, X_val, X_test, y_train, y_val, y_test\n",
    "            del X_train_scaled, X_val_scaled, X_test_scaled\n",
    "            del y_train_binary, y_val_binary, y_test_binary\n",
    "            del y_test_pred_raw, y_test_pred_cal, y_test_pred_binary\n",
    "            if 'temp_model' in locals():\n",
    "                del temp_model\n",
    "            gc.collect()\n",
    "            print(f\"🧹 Memória limpa após horizonte {horizon}\")\n",
    "            \n",
    "            # Salvar modelo\n",
    "            import joblib\n",
    "            model_path = f\"{config.models_path}/xgb_{horizon}_{experiment_name if MLFLOW_AVAILABLE else 'local'}.pkl\"\n",
    "            os.makedirs(config.models_path, exist_ok=True)\n",
    "            joblib.dump({\n",
    "                'model': final_model,\n",
    "                'calibrator': calibrator,\n",
    "                'scaler': scaler,\n",
    "                'threshold': best_threshold\n",
    "            }, model_path)\n",
    "            \n",
    "            if MLFLOW_AVAILABLE:\n",
    "                import mlflow\n",
    "                mlflow.log_artifact(model_path)\n",
    "        \n",
    "        finally:\n",
    "            if MLFLOW_AVAILABLE and run_context:\n",
    "                import mlflow\n",
    "                mlflow.end_run()\n",
    "    \n",
    "    # 9. Análise comparativa entre horizontes\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"📊 ANÁLISE COMPARATIVA ENTRE HORIZONTES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        horizon: {\n",
    "            'PR-AUC': results[horizon]['metrics']['pr_auc'],\n",
    "            'F1': results[horizon]['metrics']['f1'],\n",
    "            'MCC': results[horizon]['metrics']['mcc'],\n",
    "            'Precision': results[horizon]['metrics']['precision'],\n",
    "            'Recall': results[horizon]['metrics']['recall'],\n",
    "            'Optimal_k': results[horizon]['optimal_k']\n",
    "        }\n",
    "        for horizon in horizons\n",
    "    }).T\n",
    "    \n",
    "    print(\"\\n📈 Tabela Comparativa:\")\n",
    "    print(comparison_df.round(4))\n",
    "    \n",
    "    # Identificar melhor horizonte\n",
    "    best_horizon_pr_auc = comparison_df['PR-AUC'].idxmax()\n",
    "    best_horizon_f1 = comparison_df['F1'].idxmax()\n",
    "    \n",
    "    print(f\"\\n🏆 Melhores horizontes:\")\n",
    "    print(f\"  Melhor PR-AUC: {best_horizon_pr_auc} ({comparison_df.loc[best_horizon_pr_auc, 'PR-AUC']:.4f})\")\n",
    "    print(f\"  Melhor F1:     {best_horizon_f1} ({comparison_df.loc[best_horizon_f1, 'F1']:.4f})\")\n",
    "    \n",
    "    # 10. Análise de correlação entre predições\n",
    "    print(f\"\\n🔗 Correlação entre predições dos horizontes:\")\n",
    "    pred_matrix = pd.DataFrame({\n",
    "        horizon: results[horizon]['predictions']['calibrated']\n",
    "        for horizon in horizons\n",
    "    })\n",
    "    \n",
    "    corr_matrix = pred_matrix.corr()\n",
    "    print(corr_matrix.round(3))\n",
    "    \n",
    "    # Salvar comparação\n",
    "    comparison_df.to_csv(f\"{config.reports_path}/horizon_comparison_{experiment_name if MLFLOW_AVAILABLE else 'local'}.csv\")\n",
    "    \n",
    "    # Limpeza final de memória\n",
    "    del features_with_funding, pred_matrix, corr_matrix, comparison_df\n",
    "    gc.collect()\n",
    "    print(f\"\\n🧹 Pipeline finalizado - memória limpa\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✅ Função run_multi_horizon_pipeline definida\")# %% [markdown]\n",
    "# ## 8. Pipeline LSTM para Séries Temporais\n",
    "# \n",
    "# Implementação de LSTM com:\n",
    "# - Otimização Bayesiana via Optuna\n",
    "# - PR-AUC como métrica alvo\n",
    "# - Calibração isotônica\n",
    "# - Threshold otimizado no validation\n",
    "# - Export para produção via TorchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "023d2d4e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Funções de preparação de dados sequenciais\n",
    "def make_sequences(X_df: pd.DataFrame, y_series: pd.Series, seq_len: int):\n",
    "    \"\"\"\n",
    "    Cria sequências para LSTM a partir de dados tabulares\n",
    "    \n",
    "    Args:\n",
    "        X_df: Features\n",
    "        y_series: Labels\n",
    "        seq_len: Comprimento da sequência\n",
    "        \n",
    "    Returns:\n",
    "        X_seq: Array de sequências [n_samples, seq_len, n_features]\n",
    "        y_seq: Array de labels\n",
    "        idx_seq: Índices pandas correspondentes\n",
    "    \"\"\"\n",
    "    X = X_df.values.astype(np.float32)\n",
    "    y = y_series.values.astype(np.int64)\n",
    "    idx = X_df.index\n",
    "\n",
    "    X_seq, y_seq, idx_seq = [], [], []\n",
    "    for t in range(seq_len, len(X)):\n",
    "        X_seq.append(X[t-seq_len:t])\n",
    "        y_seq.append(y[t])\n",
    "        idx_seq.append(idx[t])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq), pd.Index(idx_seq)\n",
    "\n",
    "def train_val_test_split_time(X_df: pd.DataFrame, y: pd.Series, n_splits: int = 5):\n",
    "    \"\"\"\n",
    "    Split temporal para treino/validação/teste\n",
    "    \n",
    "    Args:\n",
    "        X_df: Features\n",
    "        y: Labels\n",
    "        n_splits: Número de splits para TimeSeriesSplit\n",
    "        \n",
    "    Returns:\n",
    "        tr_idx: Índices de treino\n",
    "        va_idx: Índices de validação\n",
    "        te_idx: Índices de teste\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    splits = list(tscv.split(X_df))\n",
    "    \n",
    "    # Penúltimo split para validação\n",
    "    (tr_idx, va_idx) = splits[-2]\n",
    "    # Último split para teste\n",
    "    (tr2_idx, te_idx) = splits[-1]\n",
    "    \n",
    "    # Treino = do início até fim do penúltimo split\n",
    "    tr_idx_full = np.arange(0, va_idx[-1] + 1)\n",
    "    \n",
    "    return tr_idx_full, va_idx, te_idx\n",
    "\n",
    "def build_lstm_tensors(X_df: pd.DataFrame, y: pd.Series, seq_len: int, \n",
    "                      tr_idx, va_idx, te_idx):\n",
    "    \"\"\"\n",
    "    Prepara tensores para LSTM com escalonamento\n",
    "    \n",
    "    Args:\n",
    "        X_df: Features\n",
    "        y: Labels\n",
    "        seq_len: Comprimento da sequência\n",
    "        tr_idx, va_idx, te_idx: Índices dos splits\n",
    "        \n",
    "    Returns:\n",
    "        Tupla com tensores de treino/val/test, índices e scaler\n",
    "    \"\"\"\n",
    "    # Escalonar features com base no treino\n",
    "    scaler = StandardScaler()\n",
    "    X_train_df = X_df.iloc[tr_idx]\n",
    "    scaler.fit(X_train_df.values)\n",
    "    \n",
    "    # Aplicar escalonamento\n",
    "    Xs = pd.DataFrame(\n",
    "        scaler.transform(X_df.values), \n",
    "        index=X_df.index, \n",
    "        columns=X_df.columns\n",
    "    )\n",
    "    \n",
    "    # Gerar sequências\n",
    "    X_seq, y_seq, idx_seq = make_sequences(Xs, y, seq_len)\n",
    "    \n",
    "    # Mapear índices originais para índices da sequência\n",
    "    idx_map = pd.Series(range(len(idx_seq)), index=idx_seq)\n",
    "    \n",
    "    # Obter índices das sequências para cada split\n",
    "    tr = idx_map[idx_seq.intersection(X_df.index[tr_idx])].dropna().astype(int).values\n",
    "    va = idx_map[idx_seq.intersection(X_df.index[va_idx])].dropna().astype(int).values\n",
    "    te = idx_map[idx_seq.intersection(X_df.index[te_idx])].dropna().astype(int).values\n",
    "    \n",
    "    # Separar tensores\n",
    "    Xtr, ytr = X_seq[tr], y_seq[tr]\n",
    "    Xva, yva = X_seq[va], y_seq[va]\n",
    "    Xte, yte = X_seq[te], y_seq[te]\n",
    "    \n",
    "    return (Xtr, ytr, Xva, yva, Xte, yte, idx_seq[te], scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7be7aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo LSTM para classificação binária\n",
    "if TORCH_AVAILABLE:\n",
    "    class LSTMClassifier(nn.Module):\n",
    "        \"\"\"\n",
    "        LSTM para classificação binária de séries temporais\n",
    "        \"\"\"\n",
    "        def __init__(self, in_dim: int, hidden: int, layers: int, dropout: float):\n",
    "            super().__init__()\n",
    "            self.lstm = nn.LSTM(\n",
    "                in_dim, hidden, \n",
    "                num_layers=layers, \n",
    "                batch_first=True, \n",
    "                dropout=dropout if layers > 1 else 0\n",
    "            )\n",
    "            self.head = nn.Linear(hidden, 1)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            # x: [batch, seq, feat]\n",
    "            out, _ = self.lstm(x)\n",
    "            # Usar apenas último timestep\n",
    "            logit = self.head(out[:, -1, :])\n",
    "            return logit.squeeze(1)  # Retorna logits (sem sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3314238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de treinamento e avaliação\n",
    "if TORCH_AVAILABLE:\n",
    "    def train_one_epoch(model, optimizer, loss_fn, loader, device):\n",
    "        \"\"\"\n",
    "        Treina modelo por uma época\n",
    "        \n",
    "        Args:\n",
    "            model: Modelo LSTM\n",
    "            optimizer: Otimizador\n",
    "            loss_fn: Função de perda\n",
    "            loader: DataLoader\n",
    "            device: Device (cuda/cpu)\n",
    "            \n",
    "        Returns:\n",
    "            Loss médio da época\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping para estabilidade\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "            \n",
    "        return total_loss / len(loader.dataset)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def eval_ap(model, loader, device):\n",
    "        \"\"\"\n",
    "        Avalia modelo com Average Precision (PR-AUC)\n",
    "        \n",
    "        Args:\n",
    "            model: Modelo LSTM\n",
    "            loader: DataLoader\n",
    "            device: Device\n",
    "            \n",
    "        Returns:\n",
    "            ap: Average Precision score\n",
    "            probs: Probabilidades preditas\n",
    "            labels: Labels verdadeiros\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        probs_list, labels_list = [], []\n",
    "        \n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            probs_list.append(probs)\n",
    "            labels_list.append(yb.numpy())\n",
    "        \n",
    "        labels = np.concatenate(labels_list)\n",
    "        probs = np.concatenate(probs_list)\n",
    "        \n",
    "        ap = average_precision_score(labels, probs)\n",
    "        return ap, probs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d65e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objetivo do Optuna para LSTM\n",
    "if TORCH_AVAILABLE and OPTUNA_AVAILABLE:\n",
    "    def objective_lstm(trial, X_train, y_train, X_val, y_val, seq_len, device):\n",
    "        \"\"\"\n",
    "        Função objetivo para otimização com Optuna\n",
    "        \n",
    "        Args:\n",
    "            trial: Trial do Optuna\n",
    "            X_train, y_train: Dados de treino\n",
    "            X_val, y_val: Dados de validação\n",
    "            seq_len: Comprimento da sequência\n",
    "            device: Device (cuda/cpu)\n",
    "            \n",
    "        Returns:\n",
    "            Best Average Precision obtido\n",
    "        \"\"\"\n",
    "        # Hiperparâmetros para otimizar\n",
    "        hidden = trial.suggest_categorical(\"hidden\", [64, 128, 256])\n",
    "        layers = trial.suggest_int(\"layers\", 1, 3)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        wd = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "        \n",
    "        # Criar modelo\n",
    "        model = LSTMClassifier(\n",
    "            X_train.shape[-1], hidden, layers, dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        # BCEWithLogitsLoss com peso para desbalanceamento\n",
    "        pos_ratio = y_train.mean()\n",
    "        pos_ratio = float(pos_ratio if pos_ratio > 0 else 1e-6)\n",
    "        pos_weight = torch.tensor((1 - pos_ratio) / pos_ratio, device=device)\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        \n",
    "        # Otimizador\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=lr, \n",
    "            weight_decay=wd\n",
    "        )\n",
    "        \n",
    "        # DataLoaders\n",
    "        train_dataset = TensorDataset(\n",
    "            torch.tensor(X_train, dtype=torch.float32),\n",
    "            torch.tensor(y_train, dtype=torch.float32)\n",
    "        )\n",
    "        val_dataset = TensorDataset(\n",
    "            torch.tensor(X_val, dtype=torch.float32),\n",
    "            torch.tensor(y_val, dtype=torch.float32)\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True, \n",
    "            drop_last=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=512, \n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Treinar com early stopping via pruning\n",
    "        best_ap = 0.0\n",
    "        patience_counter = 0\n",
    "        patience = 10\n",
    "        \n",
    "        for epoch in range(60):\n",
    "            # Treinar\n",
    "            train_loss = train_one_epoch(\n",
    "                model, optimizer, loss_fn, train_loader, device\n",
    "            )\n",
    "            \n",
    "            # Avaliar\n",
    "            ap, _, _ = eval_ap(model, val_loader, device)\n",
    "            \n",
    "            # Reportar ao Optuna\n",
    "            trial.report(ap, epoch)\n",
    "            \n",
    "            # Pruning\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "            \n",
    "            # Track best\n",
    "            if ap > best_ap:\n",
    "                best_ap = ap\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "                \n",
    "        return best_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97efe3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de treinamento com Optuna\n",
    "if TORCH_AVAILABLE and OPTUNA_AVAILABLE:\n",
    "    def fit_lstm_with_optuna(Xtr, ytr, Xva, yva, n_trials=50, \n",
    "                            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        \"\"\"\n",
    "        Treina LSTM com otimização Bayesiana\n",
    "        \n",
    "        Args:\n",
    "            Xtr, ytr: Dados de treino\n",
    "            Xva, yva: Dados de validação\n",
    "            n_trials: Número de trials do Optuna\n",
    "            device: Device para treino\n",
    "            \n",
    "        Returns:\n",
    "            model: Modelo treinado\n",
    "            best_params: Melhores hiperparâmetros\n",
    "        \"\"\"\n",
    "        print(f\"\\n🔍 Otimização Bayesiana com Optuna ({n_trials} trials)\")\n",
    "        \n",
    "        # Criar estudo\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner()\n",
    "        )\n",
    "        \n",
    "        # Otimizar\n",
    "        study.optimize(\n",
    "            lambda t: objective_lstm(t, Xtr, ytr, Xva, yva, Xtr.shape[1], device),\n",
    "            n_trials=n_trials,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        print(f\"✅ Melhor AP em validação: {study.best_value:.4f}\")\n",
    "        print(f\"📊 Melhores parâmetros: {best_params}\")\n",
    "        \n",
    "        # Re-treinar com melhores parâmetros no conjunto completo (treino + val)\n",
    "        print(f\"\\n🏋️ Treinando modelo final...\")\n",
    "        \n",
    "        model = LSTMClassifier(\n",
    "            Xtr.shape[-1], \n",
    "            best_params['hidden'],\n",
    "            best_params['layers'],\n",
    "            best_params['dropout']\n",
    "        ).to(device)\n",
    "        \n",
    "        # Combinar treino e validação\n",
    "        X_combined = np.concatenate([Xtr, Xva])\n",
    "        y_combined = np.concatenate([ytr, yva])\n",
    "        \n",
    "        # Loss com peso para manter balanceamento de classes\n",
    "        pos_ratio = y_combined.mean()\n",
    "        pos_ratio = float(pos_ratio if pos_ratio > 0 else 1e-6)\n",
    "        pos_weight = torch.tensor((1 - pos_ratio) / pos_ratio, device=device)\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=best_params['lr'],\n",
    "            weight_decay=best_params['weight_decay']\n",
    "        )\n",
    "        \n",
    "        combined_dataset = TensorDataset(\n",
    "            torch.tensor(X_combined, dtype=torch.float32),\n",
    "            torch.tensor(y_combined, dtype=torch.float32)\n",
    "        )\n",
    "        \n",
    "        combined_loader = DataLoader(\n",
    "            combined_dataset,\n",
    "            batch_size=best_params['batch_size'],\n",
    "            shuffle=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        # Treinar por mais épocas (1.5x)\n",
    "        for epoch in range(90):\n",
    "            train_loss = train_one_epoch(\n",
    "                model, optimizer, loss_fn, combined_loader, device\n",
    "            )\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"  Época {epoch}: Loss = {train_loss:.4f}\")\n",
    "        \n",
    "        return model, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57c7f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibração e seleção de threshold\n",
    "if TORCH_AVAILABLE:\n",
    "    @torch.no_grad()\n",
    "    def calibrate_and_choose_threshold(model, Xva, yva, device):\n",
    "        \"\"\"\n",
    "        Calibra probabilidades e escolhe threshold ótimo\n",
    "        \n",
    "        Args:\n",
    "            model: Modelo LSTM treinado\n",
    "            Xva, yva: Dados de validação\n",
    "            device: Device\n",
    "            \n",
    "        Returns:\n",
    "            calibrator: Calibrador isotônico\n",
    "            threshold: Threshold ótimo\n",
    "        \"\"\"\n",
    "        from sklearn.isotonic import IsotonicRegression\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        # Obter probabilidades\n",
    "        Xva_tensor = torch.tensor(Xva, dtype=torch.float32).to(device)\n",
    "        logits = model(Xva_tensor)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        \n",
    "        # Calibração isotônica\n",
    "        calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "        probs_cal = calibrator.fit_transform(probs, yva)\n",
    "        \n",
    "        # Escolher threshold que maximiza F1\n",
    "        precision, recall, thresholds = precision_recall_curve(yva, probs_cal)\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-12)\n",
    "        \n",
    "        # Ignorar último elemento (threshold = 1.0)\n",
    "        best_idx = np.nanargmax(f1_scores[:-1])\n",
    "        best_threshold = float(thresholds[best_idx]) if len(thresholds) > 0 else 0.5\n",
    "        best_f1 = f1_scores[best_idx]\n",
    "        \n",
    "        print(f\"\\n📐 Calibração completa\")\n",
    "        print(f\"  Threshold ótimo: {best_threshold:.3f}\")\n",
    "        print(f\"  F1 em validação: {best_f1:.3f}\")\n",
    "        \n",
    "        # Calcular Brier score\n",
    "        from sklearn.metrics import brier_score_loss\n",
    "        brier_before = brier_score_loss(yva, probs)\n",
    "        brier_after = brier_score_loss(yva, probs_cal)\n",
    "        print(f\"  Brier Score: {brier_before:.4f} → {brier_after:.4f}\")\n",
    "        \n",
    "        return calibrator, best_threshold\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_proba(model, X, device):\n",
    "        \"\"\"\n",
    "        Prediz probabilidades para conjunto de dados\n",
    "        \n",
    "        Args:\n",
    "            model: Modelo LSTM\n",
    "            X: Features\n",
    "            device: Device\n",
    "            \n",
    "        Returns:\n",
    "            Probabilidades preditas\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        logits = model(X_tensor)\n",
    "        return torch.sigmoid(logits).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d80a7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação no teste e geração de sinais\n",
    "if TORCH_AVAILABLE:\n",
    "    def evaluate_on_test(model, Xte, yte, calibrator, threshold, test_index, device):\n",
    "        \"\"\"\n",
    "        Avalia modelo no conjunto de teste\n",
    "        \n",
    "        Args:\n",
    "            model: Modelo LSTM treinado\n",
    "            Xte, yte: Dados de teste\n",
    "            calibrator: Calibrador isotônico\n",
    "            threshold: Threshold escolhido\n",
    "            test_index: Índices do teste\n",
    "            device: Device\n",
    "            \n",
    "        Returns:\n",
    "            Dicionário com métricas e predições\n",
    "        \"\"\"\n",
    "        # Predições\n",
    "        probs = predict_proba(model, Xte, device)\n",
    "        probs_cal = calibrator.transform(probs)\n",
    "        preds = (probs_cal >= threshold).astype(int)\n",
    "        \n",
    "        # Métricas\n",
    "        ap = average_precision_score(yte, probs_cal)\n",
    "        f1 = f1_score(yte, preds)\n",
    "        acc = accuracy_score(yte, preds)\n",
    "        \n",
    "        # MCC e Brier\n",
    "        mcc = matthews_corrcoef(yte, preds)\n",
    "        brier = brier_score_loss(yte, probs_cal)\n",
    "        \n",
    "        # Confusion matrix - forçar shape 2x2 para evitar erro quando só uma classe é predita\n",
    "        cm = confusion_matrix(yte, preds, labels=[0, 1])\n",
    "        \n",
    "        # Desempacotar matriz de forma segura\n",
    "        if cm.shape == (2, 2):\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        else:\n",
    "            # Fallback se algo der errado\n",
    "            tn = fp = fn = tp = 0\n",
    "        \n",
    "        # Sinais para backtest (-1 para short, +1 para long)\n",
    "        signals = pd.Series((preds * 2 - 1), index=test_index)\n",
    "        \n",
    "        print(f\"\\n📊 Resultados no Teste:\")\n",
    "        print(f\"  AP (PR-AUC): {ap:.4f}\")\n",
    "        print(f\"  F1 Score:    {f1:.4f}\")\n",
    "        print(f\"  Accuracy:    {acc:.4f}\")\n",
    "        print(f\"  MCC:         {mcc:.4f}\")\n",
    "        print(f\"  Brier Score: {brier:.4f}\")\n",
    "        print(f\"\\n  Confusion Matrix:\")\n",
    "        print(f\"    TN: {tn:4d}  FP: {fp:4d}\")\n",
    "        print(f\"    FN: {fn:4d}  TP: {tp:4d}\")\n",
    "        \n",
    "        return {\n",
    "            \"ap\": ap,\n",
    "            \"f1\": f1,\n",
    "            \"accuracy\": acc,\n",
    "            \"mcc\": mcc,\n",
    "            \"brier\": brier,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"proba\": probs_cal,\n",
    "            \"pred\": preds,\n",
    "            \"signals\": signals\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "303d9b0f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Export para produção\n",
    "if TORCH_AVAILABLE:\n",
    "    def export_torchscript(model, in_dim, seq_len, path=\"lstm_model.pt\", device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Exporta modelo para TorchScript\n",
    "        \n",
    "        Args:\n",
    "            model: Modelo LSTM\n",
    "            in_dim: Dimensão de entrada\n",
    "            seq_len: Comprimento da sequência\n",
    "            path: Caminho para salvar\n",
    "            device: Device\n",
    "            \n",
    "        Returns:\n",
    "            Caminho do arquivo salvo\n",
    "        \"\"\"\n",
    "        model_cpu = model.to(device).eval()\n",
    "        \n",
    "        # Input dummy para tracing\n",
    "        dummy_input = torch.randn(1, seq_len, in_dim).to(device)\n",
    "        \n",
    "        # Trace e salvar\n",
    "        traced_model = torch.jit.trace(model_cpu, dummy_input)\n",
    "        traced_model.save(path)\n",
    "        \n",
    "        print(f\"✅ Modelo exportado para: {path}\")\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b3323f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline LSTM definido e pronto para uso\n"
     ]
    }
   ],
   "source": [
    "# Pipeline completo LSTM\n",
    "def run_lstm_pipeline(X_df: pd.DataFrame, \n",
    "                     y_series: pd.Series,\n",
    "                     seq_len: int = 64,\n",
    "                     n_trials: int = 20,  # Reduzido para otimização de memória\n",
    "                     device: str = None,\n",
    "                     horizon: str = \"lstm\") -> Dict:\n",
    "    \"\"\"\n",
    "    Pipeline completo para treinar LSTM com Optuna\n",
    "    \n",
    "    Args:\n",
    "        X_df: DataFrame com features\n",
    "        y_series: Series com labels binárias\n",
    "        seq_len: Comprimento das sequências (default: 64 = 16 horas em 15min)\n",
    "        n_trials: Número de trials do Optuna\n",
    "        device: Device para treino (None = auto-detectar)\n",
    "        horizon: Nome do horizonte para logging\n",
    "        \n",
    "    Returns:\n",
    "        Dicionário com resultados compatível com run_multi_horizon_backtest\n",
    "    \"\"\"\n",
    "    if not TORCH_AVAILABLE:\n",
    "        print(\"⚠️ PyTorch não disponível - pulando LSTM\")\n",
    "        return {}\n",
    "    \n",
    "    if not OPTUNA_AVAILABLE:\n",
    "        print(\"⚠️ Optuna não disponível - pulando otimização LSTM\")\n",
    "        return {}\n",
    "    \n",
    "    # Auto-detectar device\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🚀 PIPELINE LSTM - Horizonte: {horizon}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"📊 Dataset: {len(X_df)} amostras, {X_df.shape[1]} features\")\n",
    "    print(f\"⚙️  Device: {device}\")\n",
    "    print(f\"📏 Sequência: {seq_len} timesteps\")\n",
    "    \n",
    "    # 1. Split temporal\n",
    "    print(f\"\\n1️⃣ Preparando splits temporais...\")\n",
    "    tr_idx, va_idx, te_idx = train_val_test_split_time(X_df, y_series)\n",
    "    print(f\"  Treino:    {len(tr_idx)} amostras\")\n",
    "    print(f\"  Validação: {len(va_idx)} amostras\")\n",
    "    print(f\"  Teste:     {len(te_idx)} amostras\")\n",
    "    \n",
    "    # 2. Preparar tensores\n",
    "    print(f\"\\n2️⃣ Gerando sequências e escalonando features...\")\n",
    "    (Xtr, ytr, Xva, yva, Xte, yte, test_index, scaler) = build_lstm_tensors(\n",
    "        X_df, y_series, seq_len, tr_idx, va_idx, te_idx\n",
    "    )\n",
    "    print(f\"  Sequências treino: {Xtr.shape}\")\n",
    "    print(f\"  Sequências valid:  {Xva.shape}\")\n",
    "    print(f\"  Sequências teste:  {Xte.shape}\")\n",
    "    \n",
    "    # 3. Otimização com Optuna\n",
    "    print(f\"\\n3️⃣ Otimização Bayesiana...\")\n",
    "    model, best_params = fit_lstm_with_optuna(\n",
    "        Xtr, ytr, Xva, yva, n_trials=n_trials, device=device\n",
    "    )\n",
    "    \n",
    "    # 4. Calibração e threshold\n",
    "    print(f\"\\n4️⃣ Calibração de probabilidades...\")\n",
    "    calibrator, threshold = calibrate_and_choose_threshold(\n",
    "        model, Xva, yva, device\n",
    "    )\n",
    "    \n",
    "    # 5. Avaliação no teste\n",
    "    print(f\"\\n5️⃣ Avaliação no conjunto de teste...\")\n",
    "    eval_results = evaluate_on_test(\n",
    "        model, Xte, yte, calibrator, threshold, test_index, device\n",
    "    )\n",
    "    \n",
    "    # 6. Export para produção\n",
    "    print(f\"\\n6️⃣ Exportando modelo...\")\n",
    "    model_path = f\"artifacts/models/lstm_{horizon}.pt\"\n",
    "    os.makedirs(\"artifacts/models\", exist_ok=True)\n",
    "    \n",
    "    export_path = export_torchscript(\n",
    "        model, Xtr.shape[-1], seq_len, \n",
    "        path=model_path, device=\"cpu\"\n",
    "    )\n",
    "    \n",
    "    # 7. Preparar resultados no formato esperado\n",
    "    results = {\n",
    "        horizon: {\n",
    "            \"best_params\": best_params,\n",
    "            \"threshold\": threshold,\n",
    "            \"test_metrics\": {\n",
    "                \"accuracy\": eval_results[\"accuracy\"],\n",
    "                \"precision\": eval_results[\"confusion_matrix\"][1,1] / \n",
    "                            (eval_results[\"confusion_matrix\"][1,1] + \n",
    "                             eval_results[\"confusion_matrix\"][0,1] + 1e-10),\n",
    "                \"recall\": eval_results[\"confusion_matrix\"][1,1] / \n",
    "                         (eval_results[\"confusion_matrix\"][1,1] + \n",
    "                          eval_results[\"confusion_matrix\"][1,0] + 1e-10),\n",
    "                \"f1\": eval_results[\"f1\"],\n",
    "                \"pr_auc\": eval_results[\"ap\"],\n",
    "                \"mcc\": eval_results[\"mcc\"],\n",
    "                \"brier\": eval_results[\"brier\"]\n",
    "            },\n",
    "            \"test_indices\": test_index.tolist(),\n",
    "            \"predictions\": {\n",
    "                \"proba\": eval_results[\"proba\"],\n",
    "                \"binary\": eval_results[\"pred\"]\n",
    "            },\n",
    "            \"signals\": eval_results[\"signals\"],\n",
    "            \"confusion_matrix\": eval_results[\"confusion_matrix\"],\n",
    "            \"artifact\": export_path,\n",
    "            \"scaler\": scaler,\n",
    "            \"model_type\": \"lstm\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # MLflow logging se disponível\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        import mlflow\n",
    "        \n",
    "        mlflow.log_params({\n",
    "            f\"lstm_seq_len_{horizon}\": seq_len,\n",
    "            f\"lstm_device_{horizon}\": device,\n",
    "            **{f\"lstm_{k}_{horizon}\": v for k, v in best_params.items()}\n",
    "        })\n",
    "        \n",
    "        mlflow.log_metrics({\n",
    "            f\"lstm_pr_auc_test_{horizon}\": eval_results[\"ap\"],\n",
    "            f\"lstm_f1_test_{horizon}\": eval_results[\"f1\"],\n",
    "            f\"lstm_mcc_test_{horizon}\": eval_results[\"mcc\"],\n",
    "            f\"lstm_brier_test_{horizon}\": eval_results[\"brier\"]\n",
    "        })\n",
    "        \n",
    "        mlflow.log_artifact(export_path)\n",
    "    \n",
    "    print(f\"\\n✅ Pipeline LSTM completo para horizonte {horizon}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✅ Pipeline LSTM definido e pronto para uso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b176c",
   "metadata": {},
   "source": [
    "## 9. Sistema de Backtest Multi-Horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e65596fa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Usando implementação local do BacktestEngine (imports do projeto não disponíveis)\n",
      "✅ Função run_multi_horizon_backtest definida\n"
     ]
    }
   ],
   "source": [
    "# Definir BacktestConfig e BacktestEngine caso não estejam disponíveis via import local\n",
    "# NOTA: Esta é uma implementação de fallback quando os imports do projeto não estão disponíveis\n",
    "# A implementação principal está em src/backtest/engine.py\n",
    "# Ambas as implementações mantêm a mesma interface e lógica de custos\n",
    "if not LOCAL_IMPORTS_AVAILABLE:\n",
    "    print(\"⚠️ Usando implementação local do BacktestEngine (imports do projeto não disponíveis)\")\n",
    "    \n",
    "    @dataclass\n",
    "    class BacktestConfig:\n",
    "        \"\"\"Configuração para backtest - versão local de fallback\"\"\"\n",
    "        initial_capital: float = 100000\n",
    "        fee_bps: float = 5\n",
    "        slippage_bps: float = 10\n",
    "        funding_apr_est: float = 0.00\n",
    "        borrow_apr_est: float = 0.00\n",
    "        execution_rule: str = 'next_bar_open'\n",
    "        max_leverage: float = 1.0\n",
    "        position_mode: str = 'long_short'\n",
    "        \n",
    "    class BacktestEngine:\n",
    "        \"\"\"Engine simplificado de backtest\"\"\"\n",
    "        def __init__(self, config: BacktestConfig):\n",
    "            self.config = config\n",
    "            \n",
    "        def run_backtest(self, df: pd.DataFrame, signals: pd.Series):\n",
    "            \"\"\"Executa backtest com PnL real\"\"\"\n",
    "            # Garantir alinhamento de índices\n",
    "            perf = pd.DataFrame(index=signals.index)\n",
    "            perf['signals'] = signals\n",
    "            perf['close'] = df.loc[signals.index, 'close']\n",
    "            perf['returns'] = perf['close'].pct_change()\n",
    "            \n",
    "            # Estratégia: sinal em t, execução em t+1\n",
    "            perf['strategy_returns'] = perf['returns'] * perf['signals'].shift(1)\n",
    "            \n",
    "            # Aplicar custos\n",
    "            position_changes = signals.diff().abs()\n",
    "            costs = position_changes * (self.config.fee_bps + self.config.slippage_bps) / 10000\n",
    "            perf['net_returns'] = perf['strategy_returns'] - costs\n",
    "            \n",
    "            # Calcular trades com PnL real\n",
    "            trades = pd.DataFrame()\n",
    "            trade_signals = signals.diff()\n",
    "            entries = trade_signals != 0\n",
    "            \n",
    "            if entries.any():\n",
    "                entry_points = signals.index[entries]\n",
    "                trade_list = []\n",
    "                \n",
    "                for i, entry_time in enumerate(entry_points[:-1]):\n",
    "                    exit_time = entry_points[i+1]\n",
    "                    entry_idx = signals.index.get_loc(entry_time)\n",
    "                    exit_idx = signals.index.get_loc(exit_time)\n",
    "                    \n",
    "                    # PnL real baseado nos retornos\n",
    "                    trade_returns = perf['net_returns'].iloc[entry_idx+1:exit_idx+1]\n",
    "                    trade_pnl = (1 + trade_returns).prod() - 1\n",
    "                    \n",
    "                    trade_list.append({\n",
    "                        'entry_time': entry_time,\n",
    "                        'exit_time': exit_time,\n",
    "                        'pnl': trade_pnl * self.config.initial_capital\n",
    "                    })\n",
    "                \n",
    "                trades = pd.DataFrame(trade_list)\n",
    "            \n",
    "            return perf, trades\n",
    "\n",
    "def run_multi_horizon_backtest(df: pd.DataFrame,\n",
    "                              results: Dict,\n",
    "                              initial_capital: float = 100000,\n",
    "                              fee_bps: float = 5,\n",
    "                              slippage_bps: float = 10) -> Dict:\n",
    "    \"\"\"\n",
    "    Executa backtest para múltiplos horizontes e compara performance\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame com OHLC\n",
    "        results: Resultados do pipeline multi-horizonte\n",
    "        initial_capital: Capital inicial\n",
    "        fee_bps: Taxa em basis points\n",
    "        slippage_bps: Slippage em basis points\n",
    "        \n",
    "    Returns:\n",
    "        Dict com resultados de backtest por horizonte\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"📊 BACKTEST MULTI-HORIZONTE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Usar import local ou classe definida acima\n",
    "    if LOCAL_IMPORTS_AVAILABLE:\n",
    "        from src.backtest.engine import BacktestEngine, BacktestConfig\n",
    "    \n",
    "    backtest_results = {}\n",
    "    \n",
    "    for horizon, horizon_results in results.items():\n",
    "        print(f\"\\n⏱️ Backtesting horizonte: {horizon}\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # Configurar backtest\n",
    "        config = BacktestConfig(\n",
    "            initial_capital=initial_capital,\n",
    "            fee_bps=fee_bps,\n",
    "            slippage_bps=slippage_bps,\n",
    "            funding_apr_est=0.00,  # Simplificado para demo\n",
    "            execution_rule='next_bar_open'\n",
    "        )\n",
    "        \n",
    "        # Gerar sinais a partir das predições com índices corretos\n",
    "        predictions = horizon_results['predictions']['binary']\n",
    "        labels = horizon_results['labels']\n",
    "        \n",
    "        # Usar o índice do conjunto de teste após as máscaras\n",
    "        # Isso garante alinhamento correto com os dados\n",
    "        test_indices = horizon_results.get('test_indices', None)\n",
    "        if test_indices is None:\n",
    "            # Fallback se não tivermos os índices salvos\n",
    "            test_start_idx = len(df) - len(predictions)\n",
    "            test_indices = df.index[test_start_idx:test_start_idx + len(predictions)]\n",
    "        \n",
    "        signals = pd.Series(predictions * 2 - 1, index=test_indices)  # Converter 0/1 para -1/1\n",
    "        \n",
    "        # Executar backtest\n",
    "        bt_engine = BacktestEngine(config)\n",
    "        perf, trades = bt_engine.run_backtest(df.loc[signals.index], signals)\n",
    "        \n",
    "        # Métricas de trading - usar net_returns que inclui custos\n",
    "        returns = perf['net_returns'].dropna()\n",
    "        cumulative_return = (1 + returns).cumprod().iloc[-1] - 1 if len(returns) > 0 else 0\n",
    "        \n",
    "        # Sharpe Ratio\n",
    "        if returns.std() > 0:\n",
    "            sharpe = returns.mean() / returns.std() * np.sqrt(365 * 24 * 4)  # Anualizado para 15min\n",
    "        else:\n",
    "            sharpe = 0\n",
    "            \n",
    "        # Maximum Drawdown\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - running_max) / running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Calmar Ratio\n",
    "        calmar = cumulative_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "        \n",
    "        # Win rate\n",
    "        winning_trades = trades[trades['pnl'] > 0] if len(trades) > 0 else pd.DataFrame()\n",
    "        win_rate = len(winning_trades) / len(trades) if len(trades) > 0 else 0\n",
    "        \n",
    "        # Profit factor\n",
    "        gross_profit = trades[trades['pnl'] > 0]['pnl'].sum() if len(trades) > 0 else 0\n",
    "        gross_loss = abs(trades[trades['pnl'] < 0]['pnl'].sum()) if len(trades) > 0 else 0\n",
    "        profit_factor = gross_profit / gross_loss if gross_loss > 0 else 0\n",
    "        \n",
    "        # Turnover\n",
    "        position_changes = signals.diff().abs()\n",
    "        turnover = position_changes.sum() / len(signals)\n",
    "        \n",
    "        # Expected Value per trade\n",
    "        ev_per_trade = trades['pnl'].mean() if len(trades) > 0 else 0\n",
    "        \n",
    "        print(f\"\\n📈 Métricas de Trading para {horizon}:\")\n",
    "        print(f\"  Retorno Total:    {cumulative_return:+.2%}\")\n",
    "        print(f\"  Sharpe Ratio:     {sharpe:.3f}\")\n",
    "        print(f\"  Max Drawdown:     {max_drawdown:.2%}\")\n",
    "        print(f\"  Calmar Ratio:     {calmar:.3f}\")\n",
    "        print(f\"  Win Rate:         {win_rate:.2%}\")\n",
    "        print(f\"  Profit Factor:    {profit_factor:.2f}\")\n",
    "        print(f\"  Turnover:         {turnover:.3f}\")\n",
    "        print(f\"  EV per Trade:     ${ev_per_trade:.2f}\")\n",
    "        print(f\"  Num Trades:       {len(trades)}\")\n",
    "        \n",
    "        # Comparar com Buy & Hold\n",
    "        buy_hold_return = (df.loc[signals.index, 'close'].iloc[-1] / \n",
    "                          df.loc[signals.index, 'close'].iloc[0] - 1)\n",
    "        outperformance = cumulative_return - buy_hold_return\n",
    "        \n",
    "        print(f\"\\n  Buy & Hold:       {buy_hold_return:+.2%}\")\n",
    "        print(f\"  Outperformance:   {outperformance:+.2%}\")\n",
    "        \n",
    "        # Salvar resultados\n",
    "        backtest_results[horizon] = {\n",
    "            'performance': perf,\n",
    "            'trades': trades,\n",
    "            'metrics': {\n",
    "                'cumulative_return': cumulative_return,\n",
    "                'sharpe_ratio': sharpe,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'calmar_ratio': calmar,\n",
    "                'win_rate': win_rate,\n",
    "                'profit_factor': profit_factor,\n",
    "                'turnover': turnover,\n",
    "                'ev_per_trade': ev_per_trade,\n",
    "                'num_trades': len(trades),\n",
    "                'buy_hold_return': buy_hold_return,\n",
    "                'outperformance': outperformance\n",
    "            },\n",
    "            'signals': signals,\n",
    "            'returns': returns\n",
    "        }\n",
    "    \n",
    "    # Análise comparativa\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"🏆 COMPARAÇÃO ENTRE HORIZONTES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    comparison_metrics = pd.DataFrame({\n",
    "        horizon: backtest_results[horizon]['metrics']\n",
    "        for horizon in backtest_results.keys()\n",
    "    }).T\n",
    "    \n",
    "    print(\"\\n📊 Tabela Comparativa de Backtest:\")\n",
    "    print(comparison_metrics.round(3))\n",
    "    \n",
    "    # Identificar melhor horizonte por diferentes métricas\n",
    "    best_return = comparison_metrics['cumulative_return'].idxmax()\n",
    "    best_sharpe = comparison_metrics['sharpe_ratio'].idxmax()\n",
    "    best_calmar = comparison_metrics['calmar_ratio'].idxmax()\n",
    "    \n",
    "    print(f\"\\n🥇 Melhores Horizontes:\")\n",
    "    print(f\"  Melhor Retorno: {best_return} ({comparison_metrics.loc[best_return, 'cumulative_return']:+.2%})\")\n",
    "    print(f\"  Melhor Sharpe:  {best_sharpe} ({comparison_metrics.loc[best_sharpe, 'sharpe_ratio']:.3f})\")\n",
    "    print(f\"  Melhor Calmar:  {best_calmar} ({comparison_metrics.loc[best_calmar, 'calmar_ratio']:.3f})\")\n",
    "    \n",
    "    # Análise de correlação de retornos\n",
    "    print(f\"\\n🔗 Correlação entre retornos dos horizontes:\")\n",
    "    returns_df = pd.DataFrame({\n",
    "        horizon: backtest_results[horizon]['returns']\n",
    "        for horizon in backtest_results.keys()\n",
    "    })\n",
    "    \n",
    "    # Alinhar índices\n",
    "    returns_df = returns_df.dropna()\n",
    "    if len(returns_df) > 0:\n",
    "        corr_matrix = returns_df.corr()\n",
    "        print(corr_matrix.round(3))\n",
    "    \n",
    "    # Salvar resultados\n",
    "    os.makedirs(config.artifacts_path + \"/backtest\", exist_ok=True)\n",
    "    comparison_metrics.to_csv(f\"{config.artifacts_path}/backtest/horizon_backtest_comparison.csv\")\n",
    "    \n",
    "    # Plotar equity curves (opcional - salvando dados para visualização posterior)\n",
    "    equity_curves = {}\n",
    "    for horizon in backtest_results.keys():\n",
    "        returns = backtest_results[horizon]['returns']\n",
    "        equity = (1 + returns).cumprod()\n",
    "        equity_curves[horizon] = equity\n",
    "    \n",
    "    equity_df = pd.DataFrame(equity_curves)\n",
    "    equity_df.to_csv(f\"{config.artifacts_path}/backtest/equity_curves.csv\")\n",
    "    \n",
    "    print(f\"\\n✅ Resultados salvos em {config.artifacts_path}/backtest/\")\n",
    "    \n",
    "    return backtest_results\n",
    "\n",
    "print(\"✅ Função run_multi_horizon_backtest definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46742787",
   "metadata": {},
   "source": [
    "## 9. Estratégia Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2be5e8ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Função create_ensemble_signals definida\n"
     ]
    }
   ],
   "source": [
    "def create_ensemble_signals(results: Dict, \n",
    "                           weights: Dict = None,\n",
    "                           voting: str = 'soft') -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cria sinais ensemble combinando múltiplos horizontes\n",
    "    \n",
    "    Args:\n",
    "        results: Resultados do pipeline multi-horizonte\n",
    "        weights: Pesos para cada horizonte (None = igual peso)\n",
    "        voting: 'soft' (média ponderada) ou 'hard' (votação majoritária)\n",
    "        \n",
    "    Returns:\n",
    "        Series com sinais combinados\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {h: 1.0/len(results) for h in results.keys()}\n",
    "    \n",
    "    # Coletar probabilidades calibradas\n",
    "    probabilities = {}\n",
    "    for horizon, horizon_results in results.items():\n",
    "        probs = horizon_results['predictions']['calibrated']\n",
    "        probabilities[horizon] = probs\n",
    "    \n",
    "    # Criar DataFrame alinhado\n",
    "    prob_df = pd.DataFrame(probabilities)\n",
    "    \n",
    "    if voting == 'soft':\n",
    "        # Média ponderada das probabilidades\n",
    "        weighted_probs = sum(prob_df[h] * weights[h] for h in prob_df.columns)\n",
    "        # Aplicar threshold médio dos horizontes\n",
    "        avg_threshold = np.mean([results[h]['threshold'] for h in results.keys()])\n",
    "        signals = (weighted_probs >= avg_threshold).astype(int) * 2 - 1\n",
    "    else:  # voting == 'hard'\n",
    "        # Votação majoritária\n",
    "        binary_preds = pd.DataFrame({\n",
    "            h: (prob_df[h] >= results[h]['threshold']).astype(int)\n",
    "            for h in prob_df.columns\n",
    "        })\n",
    "        signals = (binary_preds.mean(axis=1) >= 0.5).astype(int) * 2 - 1\n",
    "    \n",
    "    return signals\n",
    "\n",
    "print(\"✅ Função create_ensemble_signals definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3271d42e",
   "metadata": {},
   "source": [
    "## 10. Funções de Demonstração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4e57ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funções de demonstração definidas\n"
     ]
    }
   ],
   "source": [
    "def create_sample_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cria features básicas para demonstração\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Returns\n",
    "    for period in [1, 5, 10, 20, 50]:\n",
    "        features[f'return_{period}'] = df['close'].pct_change(period)\n",
    "    \n",
    "    # Moving averages\n",
    "    for period in [10, 20, 50, 100]:\n",
    "        features[f'ma_{period}'] = df['close'].rolling(period).mean() / df['close'] - 1\n",
    "    \n",
    "    # Volume\n",
    "    features['volume_ratio'] = df['volume'] / df['volume'].rolling(20).mean()\n",
    "    features['volume_ma_20'] = df['volume'].rolling(20).mean()\n",
    "    \n",
    "    # Volatility\n",
    "    features['volatility_20'] = df['close'].pct_change().rolling(20).std()\n",
    "    features['high_low_ratio'] = df['high'] / df['low'] - 1\n",
    "    \n",
    "    # RSI\n",
    "    delta = df['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    features['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    ma_20 = df['close'].rolling(20).mean()\n",
    "    std_20 = df['close'].rolling(20).std()\n",
    "    features['bb_upper'] = (ma_20 + 2 * std_20) / df['close'] - 1\n",
    "    features['bb_lower'] = (ma_20 - 2 * std_20) / df['close'] - 1\n",
    "    features['bb_width'] = features['bb_upper'] - features['bb_lower']\n",
    "    \n",
    "    # Price position\n",
    "    features['price_position'] = (df['close'] - df['low']) / (df['high'] - df['low'])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def generate_sample_data(n_samples: int = 10000, freq: str = '15min') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gera dados OHLCV sintéticos para teste\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    dates = pd.date_range('2023-01-01', periods=n_samples, freq=freq)\n",
    "    \n",
    "    # Simular preço com tendência e volatilidade\n",
    "    returns = np.random.randn(n_samples) * 0.01  # 1% vol\n",
    "    price = 100 * np.exp(returns.cumsum())\n",
    "    \n",
    "    df = pd.DataFrame(index=dates)\n",
    "    df['close'] = price\n",
    "    \n",
    "    # Gerar OHLV a partir do close\n",
    "    df['open'] = df['close'] * (1 + np.random.randn(n_samples) * 0.001)\n",
    "    df['high'] = df[['open', 'close']].max(axis=1) * (1 + np.abs(np.random.randn(n_samples)) * 0.002)\n",
    "    df['low'] = df[['open', 'close']].min(axis=1) * (1 - np.abs(np.random.randn(n_samples)) * 0.002)\n",
    "    df['volume'] = np.random.exponential(1000, n_samples) * (1 + np.abs(returns) * 10)\n",
    "    \n",
    "    # Garantir consistência OHLC\n",
    "    df['high'] = df[['open', 'high', 'close']].max(axis=1)\n",
    "    df['low'] = df[['open', 'low', 'close']].min(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def demo_multi_horizon_pipeline():\n",
    "    \"\"\"\n",
    "    Demonstração completa do pipeline multi-horizonte\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"🚀 DEMONSTRAÇÃO DO PIPELINE MULTI-HORIZONTE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Gerar dados sintéticos\n",
    "    print(\"\\n📊 Gerando dados sintéticos...\")\n",
    "    df = generate_sample_data(n_samples=10000)\n",
    "    print(f\"  Dados gerados: {len(df)} barras de 15min\")\n",
    "    print(f\"  Período: {df.index[0]} a {df.index[-1]}\")\n",
    "    \n",
    "    # 2. Criar features\n",
    "    print(\"\\n🔧 Criando features...\")\n",
    "    features = create_sample_features(df)\n",
    "    \n",
    "    # Adicionar features de calendário\n",
    "    crypto_features = Crypto24x7Features()\n",
    "    features = pd.concat([\n",
    "        features,\n",
    "        crypto_features.create_calendar_features(df),\n",
    "        crypto_features.create_session_features(df)\n",
    "    ], axis=1)\n",
    "    \n",
    "    print(f\"  Features criadas: {len(features.columns)}\")\n",
    "    print(f\"  Features: {', '.join(features.columns[:10])}...\")\n",
    "    \n",
    "    # 3. Executar pipeline multi-horizonte\n",
    "    print(\"\\n🎯 Executando pipeline multi-horizonte...\")\n",
    "    results = run_multi_horizon_pipeline(\n",
    "        df=df,\n",
    "        features=features,\n",
    "        horizons=['15m', '30m', '60m', '120m'],\n",
    "        n_trials=10  # Reduzido para demo\n",
    "    )\n",
    "    \n",
    "    # 4. Executar backtest\n",
    "    print(\"\\n📊 Executando backtest multi-horizonte...\")\n",
    "    backtest_results = run_multi_horizon_backtest(df, results)\n",
    "    \n",
    "    # 5. Criar sinais ensemble\n",
    "    print(\"\\n🎯 Criando estratégia ensemble...\")\n",
    "    ensemble_signals = create_ensemble_signals(results, voting='soft')\n",
    "    print(f\"  Sinais ensemble criados: {len(ensemble_signals)}\")\n",
    "    \n",
    "    print(\"\\n✅ Demonstração concluída!\")\n",
    "    \n",
    "    return results, backtest_results\n",
    "\n",
    "print(\"✅ Funções de demonstração definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc9474a",
   "metadata": {},
   "source": [
    "## 11. Como Usar o Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f8a1ed1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                        GUIA DE USO DO PIPELINE                              ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "1. CONFIGURAÇÃO INICIAL:\n",
      "   ```python\n",
      "   # Configurar ambiente determinístico\n",
      "   setup_deterministic_environment(seed=42)\n",
      "\n",
      "   # Configurar projeto\n",
      "   config = ProjectConfig()\n",
      "   config.create_directories()\n",
      "   ```\n",
      "\n",
      "2. CARREGAR SEUS DADOS:\n",
      "   ```python\n",
      "   # Opção 1: Dados locais\n",
      "   df = pd.read_csv('seu_arquivo.csv', index_col='timestamp', parse_dates=True)\n",
      "\n",
      "   # Opção 2: API (se disponível)\n",
      "   from src.data.binance_loader import CryptoDataLoader\n",
      "   loader = CryptoDataLoader()\n",
      "   df = loader.fetch_ohlcv('BTCUSDT', '15m', limit=10000)\n",
      "   ```\n",
      "\n",
      "3. CRIAR FEATURES:\n",
      "   ```python\n",
      "   # Features básicas\n",
      "   features = create_sample_features(df)\n",
      "\n",
      "   # Adicionar features crypto 24/7\n",
      "   crypto_features = Crypto24x7Features()\n",
      "   # Definir período de funding baseado no contrato (480 min para maioria, 60 min para alguns)\n",
      "   funding_period = 480  # Ajustar conforme símbolo/exchange\n",
      "   features = pd.concat([\n",
      "       features,\n",
      "       crypto_features.create_calendar_features(df),\n",
      "       crypto_features.create_session_features(df),\n",
      "       crypto_features.create_funding_features(df, funding_period_minutes=funding_period)\n",
      "   ], axis=1)\n",
      "   ```\n",
      "\n",
      "4. TREINAR MODELOS MULTI-HORIZONTE:\n",
      "   ```python\n",
      "   results = run_multi_horizon_pipeline(\n",
      "       df=df,\n",
      "       features=features,\n",
      "       horizons=['15m', '30m', '60m', '120m'],\n",
      "       test_size=0.2,\n",
      "       val_size=0.2,\n",
      "       n_trials=50  # Aumentar para produção\n",
      "   )\n",
      "   ```\n",
      "\n",
      "5. EXECUTAR BACKTEST:\n",
      "   ```python\n",
      "   backtest_results = run_multi_horizon_backtest(\n",
      "       df=df,\n",
      "       results=results,\n",
      "       initial_capital=100000,\n",
      "       fee_bps=5,\n",
      "       slippage_bps=10\n",
      "   )\n",
      "   ```\n",
      "\n",
      "6. CRIAR ESTRATÉGIA ENSEMBLE:\n",
      "   ```python\n",
      "   # Combinar sinais de múltiplos horizontes\n",
      "   ensemble_signals = create_ensemble_signals(\n",
      "       results,\n",
      "       weights={'15m': 0.2, '30m': 0.3, '60m': 0.3, '120m': 0.2},\n",
      "       voting='soft'\n",
      "   )\n",
      "   ```\n",
      "\n",
      "7. DEMO RÁPIDA:\n",
      "   ```python\n",
      "   # Executar demonstração completa com dados sintéticos\n",
      "   results, backtest_results = demo_multi_horizon_pipeline()\n",
      "   ```\n",
      "\n",
      "NOTAS IMPORTANTES:\n",
      "- Sempre use dados de 15 minutos como base\n",
      "- Horizontes são múltiplos de 15min (15m, 30m, 60m, 120m)\n",
      "- PR-AUC é a métrica principal (não ROC-AUC)\n",
      "- Calibração de probabilidades é obrigatória\n",
      "- Backtest usa execução t+1 (sinal em t, execução em t+1)\n",
      "- Custos incluem fees e slippage\n",
      "\n",
      "Para mais informações, consulte a documentação em docs/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                        GUIA DE USO DO PIPELINE                              ║\n",
    "╚══════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "1. CONFIGURAÇÃO INICIAL:\n",
    "   ```python\n",
    "   # Configurar ambiente determinístico\n",
    "   setup_deterministic_environment(seed=42)\n",
    "   \n",
    "   # Configurar projeto\n",
    "   config = ProjectConfig()\n",
    "   config.create_directories()\n",
    "   ```\n",
    "\n",
    "2. CARREGAR SEUS DADOS:\n",
    "   ```python\n",
    "   # Opção 1: Dados locais\n",
    "   df = pd.read_csv('seu_arquivo.csv', index_col='timestamp', parse_dates=True)\n",
    "   \n",
    "   # Opção 2: API (se disponível)\n",
    "   from src.data.binance_loader import CryptoDataLoader\n",
    "   loader = CryptoDataLoader()\n",
    "   df = loader.fetch_ohlcv('BTCUSDT', '15m', limit=10000)\n",
    "   ```\n",
    "\n",
    "3. CRIAR FEATURES:\n",
    "   ```python\n",
    "   # Features básicas\n",
    "   features = create_sample_features(df)\n",
    "   \n",
    "   # Adicionar features crypto 24/7\n",
    "   crypto_features = Crypto24x7Features()\n",
    "   # Definir período de funding baseado no contrato (480 min para maioria, 60 min para alguns)\n",
    "   funding_period = 480  # Ajustar conforme símbolo/exchange\n",
    "   features = pd.concat([\n",
    "       features,\n",
    "       crypto_features.create_calendar_features(df),\n",
    "       crypto_features.create_session_features(df),\n",
    "       crypto_features.create_funding_features(df, funding_period_minutes=funding_period)\n",
    "   ], axis=1)\n",
    "   ```\n",
    "\n",
    "4. TREINAR MODELOS MULTI-HORIZONTE:\n",
    "   ```python\n",
    "   results = run_multi_horizon_pipeline(\n",
    "       df=df,\n",
    "       features=features,\n",
    "       horizons=['15m', '30m', '60m', '120m'],\n",
    "       test_size=0.2,\n",
    "       val_size=0.2,\n",
    "       n_trials=50  # Aumentar para produção\n",
    "   )\n",
    "   ```\n",
    "\n",
    "5. EXECUTAR BACKTEST:\n",
    "   ```python\n",
    "   backtest_results = run_multi_horizon_backtest(\n",
    "       df=df,\n",
    "       results=results,\n",
    "       initial_capital=100000,\n",
    "       fee_bps=5,\n",
    "       slippage_bps=10\n",
    "   )\n",
    "   ```\n",
    "\n",
    "6. CRIAR ESTRATÉGIA ENSEMBLE:\n",
    "   ```python\n",
    "   # Combinar sinais de múltiplos horizontes\n",
    "   ensemble_signals = create_ensemble_signals(\n",
    "       results,\n",
    "       weights={'15m': 0.2, '30m': 0.3, '60m': 0.3, '120m': 0.2},\n",
    "       voting='soft'\n",
    "   )\n",
    "   ```\n",
    "\n",
    "7. DEMO RÁPIDA:\n",
    "   ```python\n",
    "   # Executar demonstração completa com dados sintéticos\n",
    "   results, backtest_results = demo_multi_horizon_pipeline()\n",
    "   ```\n",
    "\n",
    "NOTAS IMPORTANTES:\n",
    "- Sempre use dados de 15 minutos como base\n",
    "- Horizontes são múltiplos de 15min (15m, 30m, 60m, 120m)\n",
    "- PR-AUC é a métrica principal (não ROC-AUC)\n",
    "- Calibração de probabilidades é obrigatória\n",
    "- Backtest usa execução t+1 (sinal em t, execução em t+1)\n",
    "- Custos incluem fees e slippage\n",
    "\n",
    "Para mais informações, consulte a documentação em docs/\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709541f",
   "metadata": {},
   "source": [
    "## 12. Executar Demonstração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40d74b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🚀 DEMONSTRAÇÃO DO PIPELINE MULTI-HORIZONTE\n",
      "================================================================================\n",
      "\n",
      "📊 Gerando dados sintéticos...\n",
      "  Dados gerados: 10000 barras de 15min\n",
      "  Período: 2023-01-01 00:00:00 a 2023-04-15 03:45:00\n",
      "\n",
      "🔧 Criando features...\n",
      "  Features criadas: 41\n",
      "  Features: return_1, return_5, return_10, return_20, return_50, ma_10, ma_20, ma_50, ma_100, volume_ratio...\n",
      "\n",
      "🎯 Executando pipeline multi-horizonte...\n",
      "================================================================================\n",
      "🚀 INICIANDO PIPELINE MULTI-HORIZONTE\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Optuna não está disponível",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Para executar a demonstração, descomente a linha abaixo:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results, backtest_results = \u001b[43mdemo_multi_horizon_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mdemo_multi_horizon_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# 3. Executar pipeline multi-horizonte\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🎯 Executando pipeline multi-horizonte...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m results = \u001b[43mrun_multi_horizon_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhorizons\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m15m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m30m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m60m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m120m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduzido para demo\u001b[39;49;00m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# 4. Executar backtest\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📊 Executando backtest multi-horizonte...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mrun_multi_horizon_pipeline\u001b[39m\u001b[34m(df, features, horizons, test_size, val_size, n_trials, k_range)\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mXGBoost não está disponível\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OPTUNA_AVAILABLE:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mOptuna não está disponível\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_AVAILABLE:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ MLflow não disponível - resultados não serão tracked\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: Optuna não está disponível"
     ]
    }
   ],
   "source": [
    "# Para executar a demonstração, descomente a linha abaixo:\n",
    "# results, backtest_results = demo_multi_horizon_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0f653",
   "metadata": {},
   "source": [
    "## 13. Suíte Completa de Testes - Validação de Requisitos PRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTestSuite:\n",
    "    \"\"\"\n",
    "    Suíte completa de testes para validar todos os requisitos dos PRDs\n",
    "    Inclui testes de integridade, performance e requisitos econômicos\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: ProjectConfig = None):\n",
    "        self.config = config or ProjectConfig()\n",
    "        self.test_results = {}\n",
    "        \n",
    "    def test_temporal_leakage(self, df: pd.DataFrame, features: pd.DataFrame, \n",
    "                              labels: pd.Series) -> Tuple[bool, Dict]:\n",
    "        \"\"\"\n",
    "        Teste de vazamento temporal - CRÍTICO\n",
    "        Requisito PRD: Sem vazamento temporal comprovado\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Testando vazamento temporal...\")\n",
    "        \n",
    "        passed = True\n",
    "        metrics = {}\n",
    "        \n",
    "        # Verificar se features usam informação futura\n",
    "        for col in features.columns:\n",
    "            if 'future' in col.lower() or 'next' in col.lower():\n",
    "                passed = False\n",
    "                metrics[f'feature_{col}'] = 'SUSPEITA: nome sugere informação futura'\n",
    "        \n",
    "        # Verificar correlação com retornos futuros não shiftados\n",
    "        future_returns = df['close'].pct_change().shift(-1)  # Retorno futuro\n",
    "        \n",
    "        for col in features.columns:\n",
    "            if features[col].notna().sum() > 100:  # Só testar se tiver dados suficientes\n",
    "                corr = features[col].corr(future_returns)\n",
    "                if abs(corr) > 0.95:  # Correlação muito alta é suspeita\n",
    "                    passed = False\n",
    "                    metrics[f'correlation_{col}'] = f'ALTA: {corr:.3f}'\n",
    "        \n",
    "        # Verificar alinhamento temporal de labels\n",
    "        label_returns = labels.shift(-1)  # Labels devem estar no futuro\n",
    "        label_feature_corr = labels.corr(features.mean(axis=1))\n",
    "        \n",
    "        if abs(label_feature_corr) > 0.8:\n",
    "            passed = False\n",
    "            metrics['label_alignment'] = f'PROBLEMA: correlação {label_feature_corr:.3f}'\n",
    "        \n",
    "        metrics['status'] = 'PASS' if passed else 'FAIL'\n",
    "        print(f\"  Resultado: {'✅ PASS' if passed else '❌ FAIL'}\")\n",
    "        \n",
    "        return passed, metrics\n",
    "    \n",
    "    def test_data_quality(self, df: pd.DataFrame, features: pd.DataFrame) -> Tuple[bool, Dict]:\n",
    "        \"\"\"\n",
    "        Teste de qualidade de dados\n",
    "        Requisito PRD: Dados limpos e consistentes\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Testando qualidade de dados...\")\n",
    "        \n",
    "        passed = True\n",
    "        metrics = {}\n",
    "        \n",
    "        # Verificar NaN\n",
    "        nan_ratio = features.isna().sum().sum() / (len(features) * len(features.columns))\n",
    "        metrics['nan_ratio'] = nan_ratio\n",
    "        if nan_ratio > 0.1:  # Mais de 10% NaN é problemático\n",
    "            passed = False\n",
    "        \n",
    "        # Verificar consistência OHLC\n",
    "        ohlc_errors = 0\n",
    "        ohlc_errors += (df['high'] < df['low']).sum()\n",
    "        ohlc_errors += (df['high'] < df['open']).sum()\n",
    "        ohlc_errors += (df['high'] < df['close']).sum()\n",
    "        ohlc_errors += (df['low'] > df['open']).sum()\n",
    "        ohlc_errors += (df['low'] > df['close']).sum()\n",
    "        \n",
    "        metrics['ohlc_errors'] = ohlc_errors\n",
    "        if ohlc_errors > 0:\n",
    "            passed = False\n",
    "        \n",
    "        # Verificar outliers extremos (> 10 desvios padrão)\n",
    "        outliers = 0\n",
    "        for col in features.select_dtypes(include=[np.number]).columns:\n",
    "            z_scores = np.abs(stats.zscore(features[col].dropna()))\n",
    "            outliers += (z_scores > 10).sum()\n",
    "        \n",
    "        metrics['extreme_outliers'] = outliers\n",
    "        if outliers > len(features) * 0.01:  # Mais de 1% outliers extremos\n",
    "            passed = False\n",
    "        \n",
    "        metrics['status'] = 'PASS' if passed else 'FAIL'\n",
    "        print(f\"  Resultado: {'✅ PASS' if passed else '❌ FAIL'}\")\n",
    "        \n",
    "        return passed, metrics\n",
    "    \n",
    "    def test_model_performance(self, results: Dict) -> Tuple[bool, Dict]:\n",
    "        \"\"\"\n",
    "        Teste de performance do modelo\n",
    "        Requisito PRD: PR-AUC acima do baseline, F1 adequado\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Testando performance dos modelos...\")\n",
    "        \n",
    "        passed = True\n",
    "        metrics = {}\n",
    "        \n",
    "        baseline_pr_auc = 0.5  # Baseline aleatório\n",
    "        min_acceptable_f1 = 0.3  # Mínimo aceitável para crypto\n",
    "        \n",
    "        for horizon, result in results.items():\n",
    "            horizon_metrics = result['metrics']\n",
    "            \n",
    "            # PR-AUC deve ser melhor que baseline\n",
    "            pr_auc = horizon_metrics['pr_auc']\n",
    "            metrics[f'{horizon}_pr_auc'] = pr_auc\n",
    "            if pr_auc <= baseline_pr_auc:\n",
    "                passed = False\n",
    "                metrics[f'{horizon}_pr_auc_status'] = 'FAIL: abaixo do baseline'\n",
    "            \n",
    "            # F1 score mínimo\n",
    "            f1 = horizon_metrics['f1']\n",
    "            metrics[f'{horizon}_f1'] = f1\n",
    "            if f1 < min_acceptable_f1:\n",
    "                passed = False\n",
    "                metrics[f'{horizon}_f1_status'] = 'FAIL: F1 muito baixo'\n",
    "            \n",
    "            # MCC (Matthews Correlation Coefficient)\n",
    "            mcc = horizon_metrics['mcc']\n",
    "            metrics[f'{horizon}_mcc'] = mcc\n",
    "            if mcc < 0:  # MCC negativo indica pior que aleatório\n",
    "                passed = False\n",
    "                metrics[f'{horizon}_mcc_status'] = 'FAIL: MCC negativo'\n",
    "        \n",
    "        metrics['status'] = 'PASS' if passed else 'FAIL'\n",
    "        print(f\"  Resultado: {'✅ PASS' if passed else '❌ FAIL'}\")\n",
    "        \n",
    "        return passed, metrics\n",
    "    \n",
    "    def test_calibration(self, results: Dict) -> Tuple[bool, Dict]:\n",
    "        \"\"\"\n",
    "        Teste de calibração de probabilidades\n",
    "        Requisito PRD: Calibração dentro de ±2 p.p.\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Testando calibração de probabilidades...\")\n",
    "        \n",
    "        passed = True\n",
    "        metrics = {}\n",
    "        \n",
    "        for horizon, result in results.items():\n",
    "            predictions = result['predictions']['calibrated']\n",
    "            labels = result['labels']\n",
    "            \n",
    "            # Calcular ECE (Expected Calibration Error)\n",
    "            n_bins = 10\n",
    "            bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "            bin_lowers = bin_boundaries[:-1]\n",
    "            bin_uppers = bin_boundaries[1:]\n",
    "            \n",
    "            ece = 0\n",
    "            for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "                in_bin = (predictions > bin_lower) & (predictions <= bin_upper)\n",
    "                prop_in_bin = in_bin.mean()\n",
    "                \n",
    "                if prop_in_bin > 0:\n",
    "                    accuracy_in_bin = labels[in_bin].mean()\n",
    "                    avg_confidence_in_bin = predictions[in_bin].mean()\n",
    "                    ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "            \n",
    "            metrics[f'{horizon}_ece'] = ece\n",
    "            \n",
    "            # ECE deve ser < 0.02 (2%)\n",
    "            if ece > 0.02:\n",
    "                passed = False\n",
    "                metrics[f'{horizon}_ece_status'] = f'FAIL: ECE {ece:.3f} > 0.02'\n",
    "            \n",
    "            # Brier Score (menor é melhor)\n",
    "            brier = brier_score_loss(labels, predictions)\n",
    "            metrics[f'{horizon}_brier'] = brier\n",
    "            \n",
    "            if brier > 0.25:  # Brier > 0.25 indica má calibração\n",
    "                passed = False\n",
    "                metrics[f'{horizon}_brier_status'] = f'FAIL: Brier {brier:.3f} > 0.25'\n",
    "        \n",
    "        metrics['status'] = 'PASS' if passed else 'FAIL'\n",
    "        print(f\"  Resultado: {'✅ PASS' if passed else '❌ FAIL'}\")\n",
    "        \n",
    "        return passed, metrics\n",
    "    \n",
    "    def test_economic_metrics(self, backtest_results: Dict) -> Tuple[bool, Dict]:\n",
    "        \"\"\"\n",
    "        Teste de métricas econômicas\n",
    "        Requisito PRD: Sharpe > 1.0, DSR > 0.8\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Testando métricas econômicas...\")\n",
    "        \n",
    "        passed = True\n",
    "        metrics = {}\n",
    "        \n",
    "        min_sharpe = 1.0  # Requisito PRD\n",
    "        min_dsr = 0.8     # Requisito PRD\n",
    "        max_acceptable_drawdown = 0.25  # Max 25% drawdown\n",
    "        \n",
    "        for horizon, result in backtest_results.items():\n",
    "            horizon_metrics = result['metrics']\n",
    "            \n",
    "            # Sharpe Ratio\n",
    "            sharpe = horizon_metrics['sharpe_ratio']\n",
    "            metrics[f'{horizon}_sharpe'] = sharpe\n",
    "            if sharpe < min_sharpe:\n",
    "                passed = False\n",
    "                metrics[f'{horizon}_sharpe_status'] = f'FAIL: Sharpe {sharpe:.2f} < {min_sharpe}'\n",
    "            \n",
    "            # Maximum Drawdown\n",
    "            mdd = abs(horizon_metrics['max_drawdown'])\n",
    "            metrics[f'{horizon}_max_drawdown'] = mdd\n",
    "            if mdd > max_acceptable_drawdown:\n",
    "                passed = False\n",
    "                metrics[f'{horizon}_mdd_status'] = f'FAIL: MDD {mdd:.2%} > {max_acceptable_drawdown:.0%}'\n",
    "            \n",
    "            # Calmar Ratio\n",
    "            calmar = horizon_metrics['calmar_ratio']\n",
    "            metrics[f'{horizon}_calmar'] = calmar\n",
    "            \n",
    "            # Win Rate\n",
    "            win_rate = horizon_metrics['win_rate']\n",
    "            metrics[f'{horizon}_win_rate'] = win_rate\n",
    "            if win_rate < 0.45:  # Win rate muito baixo\n",
    "                metrics[f'{horizon}_win_rate_status'] = f'WARNING: Win rate {win_rate:.1%} baixo'\n",
    "            \n",
    "            # Calcular DSR (Deflated Sharpe Ratio) simplificado\n",
    "            # DSR = Sharpe * sqrt(T) / sqrt(1 + skew^2/4 + (kurt-3)^2/24)\n",
    "            returns = result.get('returns', pd.Series([0]))\n",
    "            if len(returns) > 30:\n",
    "                skew = returns.skew()\n",
    "                kurt = returns.kurt()\n",
    "                T = len(returns) / (365 * 24 * 4)  # Anos de dados\n",
    "                dsr = sharpe * np.sqrt(T) / np.sqrt(1 + skew**2/4 + (kurt-3)**2/24)\n",
    "                metrics[f'{horizon}_dsr'] = dsr\n",
    "                \n",
    "                if dsr < min_dsr:\n",
    "                    passed = False\n",
    "                    metrics[f'{horizon}_dsr_status'] = f'FAIL: DSR {dsr:.2f} < {min_dsr}'\n",
    "        \n",
    "        metrics['status'] = 'PASS' if passed else 'FAIL'\n",
    "        print(f\"  Resultado: {'✅ PASS' if passed else '❌ FAIL'}\")\n",
    "        \n",
    "        return passed, metrics\n",
    "    \n",
    "    def test_feature_importance_stability(self, results: Dict) -> Tuple[bool, Dict]:\n",
    "        \"\"\"\n",
    "        Teste de estabilidade das feature importances\n",
    "        Requisito PRD: Feature importances consistentes\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Testando estabilidade de feature importance...\")\n",
    "        \n",
    "        passed = True\n",
    "        metrics = {}\n",
    "        \n",
    "        # Coletar top features de cada horizonte\n",
    "        top_features_by_horizon = {}\n",
    "        for horizon, result in results.items():\n",
    "            top_10 = result['feature_importance'].head(10)['feature'].tolist()\n",
    "            top_features_by_horizon[horizon] = set(top_10)\n",
    "        \n",
    "        # Verificar overlap entre horizontes\n",
    "        horizons = list(results.keys())\n",
    "        for i in range(len(horizons)-1):\n",
    "            h1, h2 = horizons[i], horizons[i+1]\n",
    "            overlap = len(top_features_by_horizon[h1] & top_features_by_horizon[h2])\n",
    "            overlap_ratio = overlap / 10\n",
    "            \n",
    "            metrics[f'overlap_{h1}_{h2}'] = overlap_ratio\n",
    "            \n",
    "            if overlap_ratio < 0.3:  # Menos de 30% de overlap é suspeito\n",
    "                passed = False\n",
    "                metrics[f'overlap_{h1}_{h2}_status'] = f'FAIL: apenas {overlap_ratio:.1%} overlap'\n",
    "        \n",
    "        metrics['status'] = 'PASS' if passed else 'FAIL'\n",
    "        print(f\"  Resultado: {'✅ PASS' if passed else '❌ FAIL'}\")\n",
    "        \n",
    "        return passed, metrics\n",
    "    \n",
    "    def test_execution_realism(self, backtest_results: Dict) -> Tuple[bool, Dict]:\n",
    "        \"\"\"\n",
    "        Teste de realismo da execução\n",
    "        Requisito: Execução t+1, custos aplicados\n",
    "        \"\"\"\n",
    "        print(\"\\n🔍 Testando realismo da execução...\")\n",
    "        \n",
    "        passed = True\n",
    "        metrics = {}\n",
    "        \n",
    "        for horizon, result in backtest_results.items():\n",
    "            # Verificar turnover\n",
    "            turnover = result['metrics'].get('turnover', 0)\n",
    "            metrics[f'{horizon}_turnover'] = turnover\n",
    "            \n",
    "            if turnover > 10:  # Turnover muito alto é irrealista\n",
    "                passed = False\n",
    "                metrics[f'{horizon}_turnover_status'] = f'FAIL: turnover {turnover:.1f} muito alto'\n",
    "            \n",
    "            # Verificar se custos foram aplicados\n",
    "            if 'outperformance' in result['metrics']:\n",
    "                outperf = result['metrics']['outperformance']\n",
    "                if outperf > 0.5:  # Outperformance > 50% é suspeito\n",
    "                    metrics[f'{horizon}_outperf_warning'] = f'WARNING: outperformance {outperf:.1%} muito alto'\n",
    "        \n",
    "        metrics['status'] = 'PASS' if passed else 'FAIL'\n",
    "        print(f\"  Resultado: {'✅ PASS' if passed else '❌ FAIL'}\")\n",
    "        \n",
    "        return passed, metrics\n",
    "    \n",
    "    def run_all_tests(self, df: pd.DataFrame, features: pd.DataFrame, \n",
    "                      results: Dict, backtest_results: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Executa todos os testes e gera relatório completo\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"🧪 EXECUTANDO SUÍTE COMPLETA DE TESTES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        all_results = {}\n",
    "        \n",
    "        # Preparar labels para teste (usar do primeiro horizonte)\n",
    "        first_horizon = list(results.keys())[0]\n",
    "        labeler = results[first_horizon]['labeler']\n",
    "        labels = labeler.create_labels(df)\n",
    "        \n",
    "        # 1. Teste de vazamento temporal\n",
    "        passed, metrics = self.test_temporal_leakage(df, features, labels)\n",
    "        all_results['temporal_leakage'] = {'passed': passed, 'metrics': metrics}\n",
    "        \n",
    "        # 2. Teste de qualidade de dados\n",
    "        passed, metrics = self.test_data_quality(df, features)\n",
    "        all_results['data_quality'] = {'passed': passed, 'metrics': metrics}\n",
    "        \n",
    "        # 3. Teste de performance do modelo\n",
    "        passed, metrics = self.test_model_performance(results)\n",
    "        all_results['model_performance'] = {'passed': passed, 'metrics': metrics}\n",
    "        \n",
    "        # 4. Teste de calibração\n",
    "        passed, metrics = self.test_calibration(results)\n",
    "        all_results['calibration'] = {'passed': passed, 'metrics': metrics}\n",
    "        \n",
    "        # 5. Teste de métricas econômicas\n",
    "        passed, metrics = self.test_economic_metrics(backtest_results)\n",
    "        all_results['economic_metrics'] = {'passed': passed, 'metrics': metrics}\n",
    "        \n",
    "        # 6. Teste de estabilidade de features\n",
    "        passed, metrics = self.test_feature_importance_stability(results)\n",
    "        all_results['feature_stability'] = {'passed': passed, 'metrics': metrics}\n",
    "        \n",
    "        # 7. Teste de realismo de execução\n",
    "        passed, metrics = self.test_execution_realism(backtest_results)\n",
    "        all_results['execution_realism'] = {'passed': passed, 'metrics': metrics}\n",
    "        \n",
    "        # Resumo final\n",
    "        self.print_test_summary(all_results)\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def print_test_summary(self, results: Dict):\n",
    "        \"\"\"\n",
    "        Imprime resumo dos testes\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"📊 RESUMO DOS TESTES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        total_tests = len(results)\n",
    "        passed_tests = sum(1 for r in results.values() if r['passed'])\n",
    "        \n",
    "        print(f\"\\nTotal de testes: {total_tests}\")\n",
    "        print(f\"Testes aprovados: {passed_tests}\")\n",
    "        print(f\"Taxa de aprovação: {passed_tests/total_tests:.1%}\")\n",
    "        \n",
    "        print(\"\\n📋 Detalhes por teste:\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        for test_name, result in results.items():\n",
    "            status = \"✅ PASS\" if result['passed'] else \"❌ FAIL\"\n",
    "            print(f\"{test_name:25s}: {status}\")\n",
    "            \n",
    "            # Mostrar métricas críticas se falhou\n",
    "            if not result['passed']:\n",
    "                for key, value in result['metrics'].items():\n",
    "                    if 'FAIL' in str(value) or 'status' in key:\n",
    "                        print(f\"  └─ {key}: {value}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        # Verificação dos requisitos PRD\n",
    "        print(\"\\n🎯 REQUISITOS PRD:\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        # Requisitos críticos\n",
    "        requirements = {\n",
    "            'Sem vazamento temporal': results['temporal_leakage']['passed'],\n",
    "            'PR-AUC acima do baseline': 'model_performance' in results and results['model_performance']['passed'],\n",
    "            'Sharpe > 1.0': False,  # Verificar nas métricas\n",
    "            'DSR > 0.8': False,  # Verificar nas métricas\n",
    "            'Calibração < 2%': results.get('calibration', {}).get('passed', False),\n",
    "            'Features estáveis': results.get('feature_stability', {}).get('passed', False)\n",
    "        }\n",
    "        \n",
    "        # Verificar Sharpe e DSR\n",
    "        if 'economic_metrics' in results:\n",
    "            metrics = results['economic_metrics']['metrics']\n",
    "            # Verificar se algum horizonte passou no Sharpe\n",
    "            sharpe_passed = any(\n",
    "                metrics.get(f'{h}_sharpe', 0) >= 1.0 \n",
    "                for h in ['15m', '30m', '60m', '120m']\n",
    "            )\n",
    "            requirements['Sharpe > 1.0'] = sharpe_passed\n",
    "            \n",
    "            # Verificar DSR\n",
    "            dsr_passed = any(\n",
    "                metrics.get(f'{h}_dsr', 0) >= 0.8\n",
    "                for h in ['15m', '30m', '60m', '120m']\n",
    "                if f'{h}_dsr' in metrics\n",
    "            )\n",
    "            requirements['DSR > 0.8'] = dsr_passed\n",
    "        \n",
    "        for req, passed in requirements.items():\n",
    "            status = \"✅\" if passed else \"❌\"\n",
    "            print(f\"{status} {req}\")\n",
    "        \n",
    "        # Conclusão\n",
    "        all_requirements_met = all(requirements.values())\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        if all_requirements_met:\n",
    "            print(\"🎉 TODOS OS REQUISITOS PRD FORAM ATENDIDOS!\")\n",
    "        else:\n",
    "            print(\"⚠️ ALGUNS REQUISITOS PRD NÃO FORAM ATENDIDOS\")\n",
    "            print(\"   Revise os testes falhados e ajuste o modelo\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "\n",
    "# Função para executar os testes\n",
    "def run_model_tests(df: pd.DataFrame = None, features: pd.DataFrame = None,\n",
    "                    results: Dict = None, backtest_results: Dict = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Executa a suíte completa de testes\n",
    "    \n",
    "    Se não fornecer dados, executa com dados de demo\n",
    "    \"\"\"\n",
    "    if df is None or features is None or results is None:\n",
    "        print(\"Gerando dados de demonstração para testes...\")\n",
    "        df = generate_sample_data(10000)\n",
    "        features = create_sample_features(df)\n",
    "        \n",
    "        # Adicionar features crypto\n",
    "        crypto_features = Crypto24x7Features()\n",
    "        features = pd.concat([\n",
    "            features,\n",
    "            crypto_features.create_calendar_features(df),\n",
    "            crypto_features.create_session_features(df)\n",
    "        ], axis=1)\n",
    "        \n",
    "        # Executar pipeline\n",
    "        print(\"Executando pipeline para gerar resultados...\")\n",
    "        results = run_multi_horizon_pipeline(\n",
    "            df, features, \n",
    "            horizons=['15m', '30m'],  # Menos horizontes para teste rápido\n",
    "            n_trials=5  # Poucos trials para teste\n",
    "        )\n",
    "        \n",
    "        # Executar backtest\n",
    "        print(\"Executando backtest...\")\n",
    "        backtest_results = run_multi_horizon_backtest(df, results)\n",
    "    \n",
    "    # Executar testes\n",
    "    test_suite = ModelTestSuite()\n",
    "    test_results = test_suite.run_all_tests(df, features, results, backtest_results)\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "\n",
    "# Para executar os testes:\n",
    "# test_results = run_model_tests()\n",
    "\n",
    "print(\"✅ Suíte de testes definida\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
