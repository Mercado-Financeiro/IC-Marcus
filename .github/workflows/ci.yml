name: CI/CD Pipeline - Cryptocurrency Trading System

on:
  push:
    branches: [ main, develop, trading-system-mvp ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Executa testes diariamente às 2h UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  TENSORFLOW_VERSION: '2.15.0'
  PYTHONPATH: ./src

jobs:
  # Job 1: Testes Rápidos (Unitários)
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    strategy:
      matrix:
        python-version: ['3.10', '3.11']

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: false  # Não baixar arquivos grandes para testes unitários

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential wget
        # Install TA-Lib
        wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz
        tar -xzf ta-lib-0.4.0-src.tar.gz
        cd ta-lib/
        ./configure --prefix=/usr
        make
        sudo make install
        cd ..

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install numpy  # Install numpy first for TA-Lib
        pip install TA-Lib  # Install TA-Lib with system dependency
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-mock pytest-xdist

    - name: Configure environment
      run: |
        # Desabilitar GPU para testes
        echo "CUDA_VISIBLE_DEVICES=-1" >> $GITHUB_ENV
        echo "TF_CPP_MIN_LOG_LEVEL=2" >> $GITHUB_ENV

        # Criar diretórios de teste
        mkdir -p tests/temp
        mkdir -p logs

    - name: Run unit tests
      run: |
        pytest tests/unit/ \
          --verbose \
          --tb=short \
          --cov=src/ic_core \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --maxfail=5 \
          -m "unit and not slow"

    - name: Upload coverage to Codecov
      if: matrix.python-version == '3.11'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Job 2: Testes de Integração
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: unit-tests

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: false

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-mock pytest-timeout

    - name: Create sample data
      run: |
        python -c "
        import pandas as pd
        import numpy as np

        # Criar dados de teste
        np.random.seed(42)
        n = 5000
        data = {
            'timestamp': pd.date_range('2023-01-01', periods=n, freq='5T'),
            'open': 50000 + np.random.randn(n) * 1000,
            'high': 50000 + np.random.randn(n) * 1000 + 500,
            'low': 50000 + np.random.randn(n) * 1000 - 500,
            'close': 50000 + np.random.randn(n) * 1000,
            'volume': np.random.exponential(1000, n)
        }
        df = pd.DataFrame(data)
        df['high'] = np.maximum(df[['open', 'close']].max(axis=1), df['high'])
        df['low'] = np.minimum(df[['open', 'close']].min(axis=1), df['low'])

        # Salvar dados de teste
        import os
        os.makedirs('src/ic_core/data/raw', exist_ok=True)
        df.to_parquet('src/ic_core/data/raw/btc_5m_complete.parquet', index=False)
        print(f'Created test data: {len(df)} samples')
        "

    - name: Run integration tests
      run: |
        pytest tests/integration/ \
          --verbose \
          --tb=short \
          --timeout=300 \
          -m "integration and not slow"

    - name: Check for memory leaks
      run: |
        python -c "
        import psutil
        import gc

        # Simular pipeline e verificar memória
        process = psutil.Process()
        memory_before = process.memory_info().rss / 1024 / 1024

        # Simular processamento
        data = list(range(100000))
        del data
        gc.collect()

        memory_after = process.memory_info().rss / 1024 / 1024
        memory_growth = memory_after - memory_before

        print(f'Memory before: {memory_before:.1f}MB')
        print(f'Memory after: {memory_after:.1f}MB')
        print(f'Memory growth: {memory_growth:.1f}MB')

        if memory_growth > 100:
            raise Exception(f'Potential memory leak: {memory_growth:.1f}MB growth')
        "

  # Job 3: Testes de Regressão (Bugs Corrigidos)
  regression-tests:
    name: Regression Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: unit-tests

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: false

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest

    - name: Test bug fixes
      run: |
        pytest tests/regression/ \
          --verbose \
          --tb=short \
          -m "regression"

  # Job 4: Code Quality
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: false

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install black isort flake8 mypy bandit safety

    - name: Check code formatting (Black)
      run: |
        black --check --diff src/ic_core/

    - name: Check import sorting (isort)
      run: |
        isort --check-only --diff src/ic_core/

    - name: Lint with flake8
      run: |
        flake8 src/ic_core/ --max-line-length=88 --extend-ignore=E203,W503,E402
        flake8 tests/ --max-line-length=88 --extend-ignore=E203,W503,E402

    - name: Security scan (Bandit)
      run: |
        bandit -r core/ -f json -o bandit-report.json || true

    - name: Check dependencies (Safety)
      run: |
        safety check --json --output safety-report.json || true

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # Job 5: Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [unit-tests, integration-tests]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: false

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark memory-profiler

    - name: Run performance tests
      run: |
        pytest tests/ \
          --verbose \
          --benchmark-only \
          --benchmark-json=benchmark-results.json \
          -m "slow"

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: benchmark-results.json

  # Job 6: Docker Build Test
  docker-test:
    name: Docker Build Test
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [unit-tests, code-quality]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        lfs: false

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build Docker image
      run: |
        # Criar Dockerfile de teste se não existir
        if [ ! -f Dockerfile ]; then
          cat > Dockerfile << EOF
        FROM python:3.11-slim

        WORKDIR /app
        COPY requirements.txt .
        RUN pip install --no-cache-dir -r requirements.txt

        COPY core/ ./core/
        COPY tests/ ./tests/

        CMD ["python", "-m", "pytest", "tests/unit/", "-v"]
        EOF
        fi

        docker build -t crypto-trading-system:test .

    - name: Test Docker container
      run: |
        docker run --rm crypto-trading-system:test || true

  # Job 7: Notification
  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, regression-tests, code-quality]
    if: always()

    steps:
    - name: Notify success
      if: ${{ needs.unit-tests.result == 'success' && needs.integration-tests.result == 'success' }}
      run: |
        echo "✅ All tests passed successfully!"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Regression Tests: ${{ needs.regression-tests.result }}"
        echo "Code Quality: ${{ needs.code-quality.result }}"

    - name: Notify failure
      if: ${{ needs.unit-tests.result == 'failure' || needs.integration-tests.result == 'failure' }}
      run: |
        echo "❌ Tests failed!"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Regression Tests: ${{ needs.regression-tests.result }}"
        echo "Code Quality: ${{ needs.code-quality.result }}"
        exit 1
