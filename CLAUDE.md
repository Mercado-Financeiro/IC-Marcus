# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Notebook Policy (OBRIGAT√ìRIO)

- O notebook `notebooks/IC_Crypto_Complete.ipynb` √© **console de orquestra√ß√£o** (EDA, execu√ß√£o de rotinas, visualiza√ß√µes, experimentos).
- **Fonte da verdade** do c√≥digo fica em `src/**`. Toda l√≥gica de dados, features, modelos, backtest e p√≥s-processamento deve residir em m√≥dulos import√°veis.
- **Pareamento Jupytext**: `ipynb,py:percent` obrigat√≥rio. Commits que alterem `.ipynb` sem atualizar o par `.py` **falham no CI**.
- **Regra cr√≠tica**: TODO desenvolvimento e experimento DEVE ser feito no notebook `notebooks/IC_Crypto_Complete.ipynb`, aplicando otimiza√ß√µes de mem√≥ria sempre que poss√≠vel.

---

# CLAUDE.md ‚Äî Manual de Opera√ß√µes do Projeto (v2)

> Manual para IA atuar como engenheiro aut√¥nomo em um projeto de **Machine Learning para mercado financeiro**: treinar modelos com **dataset interno**, entregar **dashboard**, aplicar **MLOps** e manter **mem√≥ria viva do c√≥digo**. **N√£o emitir recomenda√ß√µes de investimento.**

---

## TL;DR

* **Objetivo**: pipeline reprodut√≠vel de pesquisa/trading com XGBoost e LSTM, backtest realista e dashboard Streamlit.
* **Garantias**: CV temporal sem vazamento, **calibra√ß√£o de probabilidades + threshold tuning obrigat√≥rios**, tracking com MLflow, dados versionados (DVC opc.), testes, lint e tipagem.
* **Determinismo**: seeds unificadas (Python/NumPy/Torch), cuDNN determin√≠stico, CUBLAS workspace configurado.
* **Execu√ß√£o t+1**: sinal gerado na barra t e executado na abertura da barra t+1 com slippage.
* **M√©trica de decis√£o**: al√©m de F1/PR-AUC, **threshold por EV l√≠quido** em valida√ß√£o sob custos.
* **Mem√≥ria**: atualizar `AI_MEMORY.md` e `CODE_MAP.md` a cada tarefa.

---

## QUICK COMMANDS (cart√£o de bolso)

```
Instala√ß√£o dev  : make install
Determinismo    : make deterministic
Formatar c√≥digo : make fmt
Tipos           : make type
Testes          : make test
Treinar XGB     : make train MODEL=xgb
Treinar LSTM    : make train MODEL=lstm
Backtest        : make backtest
Dashboard       : make dash
```

---

## Avisos e √âtica

* Proibido interpretar como aconselhamento financeiro.
* Tratar custos, slippage e risco. Nunca reportar m√©tricas sem custos.
* Sanitizar PII. N√£o baixar dados externos sem aprova√ß√£o expl√≠cita.

---

## Regras Globais

* **Reprodutibilidade**: seeds fixas; `PYTHONHASHSEED=0`; vers√µes de libs congeladas com **lock de depend√™ncias** (hashes) e auditoria de seguran√ßa.
* **Determinismo real**: Torch determin√≠stico, cuDNN determin√≠stico, `CUBLAS_WORKSPACE_CONFIG` definido; XGBoost com par√¢metros est√°veis e CPU quando for necess√°rio reproduzir bit a bit.
* **Sem vazamento temporal**: *Purged/Embargoed K-Fold* ou *Walk-Forward Anchored*. `shuffle=False` sempre.
* **Calibra√ß√£o/Threshold**: usar `CalibratedClassifierCV` (isot√¥nica/Platt) em valida√ß√£o e **fixar threshold** antes de avaliar em teste; reportar **Brier score**. Registrar tamb√©m **threshold que maximiza EV l√≠quido**.
* **Execu√ß√£o t+1**: decis√µes calculadas na barra t e ordens executadas na **abertura** de t+1.
* **M√©tricas ML**: F1, MCC, AUC, PR-AUC, Brier. **M√©tricas Trading**: Sharpe, Sortino, Calmar, retorno l√≠quido, MDD, turnover, EV.
* **Config centralizada**: `configs/*.yaml` via argparse/Hydra-like simples.
* **Qualidade**: Python 3.11+, type hints, docstrings Google-style; `ruff`, `black`, `mypy`, `bandit`.
* **Pipelines**: `sklearn.Pipeline` e serializa√ß√£o; artefatos em `artifacts/`.
* **Tracking**: MLflow local em `artifacts/mlruns` com tags obrigat√≥rias: `git_commit`, `dataset_sha256`, `config_sha256`, `degraded_mode`, `prd_name`, `prd_version`, `prd_sha256`, `exec_rule`.
* **Versionamento de dados**: DVC (opcional) sobre `data/` com *remote* S3-compat√≠vel.
* **Segredos**: `.env` via `pydantic-settings`; nunca commitar chaves.
* **Observabilidade**: logging estruturado (`structlog`); logs por run.
* **Timezone e unidades**: timestamps **timezone-aware (UTC)**; contrato `{returns: log, costs: bps}` em todo o projeto.

---

## Estrutura de Pastas (alvo)

```
.
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ data/        # loaders e valida√ß√µes (pandera)
‚îÇ  ‚îú‚îÄ features/    # engenharia (lags, rolling, volatilidade, indicadores)
‚îÇ  ‚îú‚îÄ models/      # treino/infer√™ncia (baseline, xgb, lstm, postproc)
‚îÇ  ‚îú‚îÄ backtest/    # motor de simula√ß√£o e m√©tricas financeiras
‚îÇ  ‚îú‚îÄ utils/       # logging, seeds, custos, configs
‚îÇ  ‚îî‚îÄ dashboard/   # app Streamlit
‚îú‚îÄ notebooks/      # EDA apenas; c√≥digo final vai para src/
‚îú‚îÄ configs/        # *.yaml (dados, xgb, lstm, backtest, agent)
‚îú‚îÄ tests/          # pytest + hypothesis
‚îú‚îÄ data/{raw,processed}
‚îú‚îÄ artifacts/      # modelos, relat√≥rios, figuras, mlruns/
‚îú‚îÄ .dvc/           # se DVC habilitado
‚îú‚îÄ AI_MEMORY.md    # mem√≥ria viva (estado)
‚îú‚îÄ CODE_MAP.md     # entrypoints e mapas
‚îú‚îÄ ARCHITECTURE.md # vis√£o do sistema
‚îú‚îÄ EXPERIMENTS.md  # tabela de experimentos
‚îú‚îÄ Makefile
‚îú‚îÄ requirements.txt    # lock com hashes (gerado)
‚îî‚îÄ README.md
```

---

## Stack t√©cnico

* **Core**: numpy, pandas, scikit-learn, xgboost, torch, optuna, pandera, pydantic-settings, structlog
* **MLOps**: mlflow, dvc\[s3] (opcional), pre-commit, pytest, hypothesis, ruff, black, mypy, bandit, pip-audit, gitleaks
* **Dashboard**: streamlit, plotly/matplotlib

### `pyproject.toml` (trecho m√≠nimo)

```toml
[project]
name = "ml-finance"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
  "numpy", "pandas", "scikit-learn", "xgboost",
  "torch", "optuna", "mlflow", "pandera",
  "pydantic-settings", "structlog", "streamlit",
  "matplotlib", "plotly"
]

[project.optional-dependencies]
dev = [
  "pytest", "hypothesis", "ruff", "black", "mypy", "bandit", "pre-commit",
  "pip-tools", "pip-audit", "gitleaks"
]
```

> **Lock de depend√™ncias**: gere `requirements.txt` com hashes via `pip-compile --generate-hashes` e commite o lock.

### `.env.example`

```
MLFLOW_TRACKING_URI=artifacts/mlruns
DVC_REMOTE_URL=s3://bucket/projeto
DASHBOARD_PORT=8501
```

### `.pre-commit-config.yaml` (resumo)

```yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.6.9
    hooks: [{id: ruff},{id: ruff-format}]
  - repo: https://github.com/psf/black
    rev: 24.8.0
    hooks: [{id: black}]
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.10.0
    hooks: [{id: mypy}]
  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.9
    hooks: [{id: bandit}]
  - repo: https://github.com/pypa/pip-audit
    rev: v2.7.3
    hooks: [{id: pip-audit, args: ["-r","requirements.txt","--strict"], additional_dependencies: ["pip-audit==2.7.3"]}]
  - repo: https://github.com/gitleaks/gitleaks
    rev: v8.18.4
    hooks: [{id: gitleaks}]
```

### Jupytext (Notebooks)

* N√£o editar arquivos `.ipynb` diretamente; trabalhar no par em texto `*.py` no formato percent (`# %%`).
* Pareamento obrigat√≥rio via `.jupytext.toml` com `formats = "ipynb,py:percent"`.
* Sincronizar pares: `jupytext --sync notebooks/*.ipynb`.
* Ignorar checkpoints: `**/.ipynb_checkpoints/**`.

Quickstart:

```bash
pip install jupytext
jupytext --set-formats "ipynb,py:percent" notebooks/*.ipynb
jupytext --sync notebooks/*.ipynb
```

Opcional (pre-commit):

```yaml
- repo: https://github.com/mwouts/jupytext
  rev: v1.16.2
  hooks:
    - id: jupytext
      args: [--sync]
      files: ^notebooks/.*\.(ipynb|py)$
```

---

## Loop do Desenvolvedor (executar para cada solicita√ß√£o)

### 1) Planejar

* Registrar em `AI_MEMORY.md`: objetivo, insumos, sa√≠das, aceita√ß√£o, riscos (leak, overfit, lat√™ncia).
* Definir parti√ß√µes temporais: treino/valida√ß√£o/teste fora da janela.
* Escolher modelo(s) e m√©tricas (ML e Trading) e custos padr√£o.

### 2) Desenvolver

* **Dados**: `src/data/loaders.py` com valida√ß√£o `pandera`; `src/data/splits.py` com PurgedKFold/WalkForward.
* **Features**: `src/features/pipeline.py` com transforms compon√≠veis; normalizar por treino.
* **Modelos**:

  * `src/models/xgb.py`: treino com TimeSeriesSplit, Optuna opcional; import√¢ncias SHAP/permutation.
  * `src/models/lstm.py`: janelas, m√°scara temporal, early stopping; escalonador fitado no treino; **Torch determin√≠stico**.
  * `src/models/baseline.py`: sinais simples (momentum/mean-reversion) para calibrar expectativa.
* **Postproc**: `src/models/postproc.py` com calibra√ß√£o e sele√ß√£o de threshold por F1/PR-AUC **e** por **EV l√≠quido**.
* **Backtest**: `src/backtest/engine.py` com sizing, custos fixos e proporcionais, slippage, funding/borrow fee pr√≥‚Äërata, restri√ß√£o de alavancagem, hor√°rios de negocia√ß√£o e **execu√ß√£o t+1**.
* **Dashboard**: `src/dashboard/app.py` com p√°ginas: runs MLflow, equity curve, drawdown, distribui√ß√£o de retornos, matriz de confus√£o, import√¢ncia de features, compara√ß√£o de estrat√©gias e **aba de Threshold Tuning/EV**.
* **Logging/Tracking**: logar par√¢metros, m√©tricas e artefatos em MLflow; salvar figuras em `artifacts/`.

### 3) Testar

* Unit√°rios: splits sem vazamento; shapes; serializa√ß√£o; tempo limite de treino curto.
* Property-based: `hypothesis` em transforms.
* Smoke tests: dashboard carrega; backtest roda num *toy set*.
* Validar esquema com `pandera` a cada load.

### 4) Revisar

* Rodar `ruff`, `black`, `mypy`, `bandit`, `pip-audit` e `gitleaks`.
* Refatorar fun√ß√µes longas; remover duplica√ß√µes; documentar contratos e efeitos colaterais.
* Atualizar `ARCHITECTURE.md` se estrutura mudou.

### 5) Commitar

* Conventional Commits; atualizar `EXPERIMENTS.md` e `AI_MEMORY.md`.
* Se DVC usado: `dvc add` e commitar `.dvc`.

---

## Mem√≥ria do Projeto (autogerida)

Ap√≥s cada loop, anexar em `AI_MEMORY.md`:

* Resumo da tarefa e decis√£o arquitetural.
* Arquivos tocados e entrypoints.
* Artefatos criados (paths MLflow/DVC).
* Pr√≥ximos passos e bloqueios.

Atualizar `CODE_MAP.md` com JSON curto:

```json
{
  "entrypoints": {
    "train_xgb": "src/models/xgb.py:cli_train",
    "train_lstm": "src/models/lstm.py:cli_train",
    "backtest": "src/backtest/engine.py:run_backtest",
    "dashboard": "src/dashboard/app.py:main"
  },
  "configs": [
    "configs/data.yaml",
    "configs/xgb.yaml",
    "configs/lstm.yaml",
    "configs/backtest.yaml"
  ],
  "datasets": {
    "bars": "data/processed/<symbol>_<freq>.parquet",
    "features": "data/processed/<symbol>_<freq>_features.parquet"
  },
  "hashes": {
    "dataset": "<sha256>",
    "libs_freeze": "<pip-freeze-hash>"
  },
  "prd": {
    "xgb": "docs/prd/PRD_XGB.md",
    "lstm": "docs/prd/PRD_LSTM.md"
  }
}
```

---

## Regras de Sentinela contra Vazamento (Leakage Guards)

**Sempre provar com asserts e logs** em cada run:

1. `max(train_time) + embargo < min(val_time)` e `< min(test_time)`.
2. `fit()` s√≥ em treino; valida√ß√£o/teste apenas `transform()`.
3. Rolling/expanding stats: fit no treino e `partial_transform` nas janelas seguintes.
4. M√©tricas de teste s√≥ ap√≥s **calibra√ß√£o + threshold** fixados na valida√ß√£o.
5. **Execu√ß√£o t+1** comprovada: timestamps de decis√£o e de execu√ß√£o registrados na run.

---

## Prioridade de Features

1. **B√°sico**: OHLCV, retornos, volatilidade realizada.
2. **T√©cnico**: RSI, m√©dias m√≥veis, z-score, bandas; janelas m√∫ltiplas.
3. **Avan√ßado**: microestrutura (spreads/imbalance), regime/vol clusters, calend√°rio.

---

## Defini√ß√£o de Pronto (DoD)

* Treino reproduz√≠vel via `make train MODEL=xgb|lstm` ou `python -m src.models.<model> --config ...`.
* `make deterministic` executado e verificado.
* `make test` passa; lints, tipos, **pip-audit** e **gitleaks** OK; lock `requirements.txt` presente e atualizado.
* **Calibra√ß√£o executada**, `Brier` reportado e **threshold** escolhido em valida√ß√£o (F1/PR-AUC) **e** `th_ev` por EV l√≠quido.
* **Execu√ß√£o t+1** habilitada e registrada (`exec_rule=next_bar_open`).
* Experimento no MLflow com m√©tricas ML e Trading e figuras anexas; tags preenchidas (`git_commit`, `dataset_sha256`, `config_sha256`, `degraded_mode`, `prd_*`).
* Dashboard `make dash` rodando com equity, drawdown, compara√ß√£o de runs e aba de **Threshold Tuning/EV**.
* Documenta√ß√£o atualizada: `AI_MEMORY.md`, `CODE_MAP.md`, `ARCHITECTURE.md`.
* **Gate**: se `temporal_leak_checks != pass`, `determinism != pass` ou `tests != pass`, **tarefa reprovada** e o agente deve retornar um novo `=== PLAN ===` de corre√ß√£o.
* **Gate PRD**: Run aprovada somente se o PLAN listar **PRD + vers√£o + sha** e as tags estiverem no MLflow.

---

## Makefile (alvo m√≠nimo)

```makefile
install:
	pip install -U pip && pip install .[dev]
	pre-commit install

fmt: ; ruff check --fix . ; black . ; ruff format .

type: ; mypy src

test: ; pytest -q

deterministic:
	python - <<'PY'
import os, random, numpy as np
try:
    import torch
    torch.use_deterministic_algorithms(True)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
except Exception:
    pass
os.environ.update({
  "PYTHONHASHSEED": "0",
  "CUBLAS_WORKSPACE_CONFIG": ":4096:8",
  "CUDA_LAUNCH_BLOCKING": "1",
})
random.seed(42); np.random.seed(42)
print("determinism:on")
PY

train:
	python -m src.models.$(MODEL) --config configs/$(MODEL).yaml

backtest:
	python -m src.backtest.engine --config configs/backtest.yaml

ash:
	streamlit run src/dashboard/app.py --server.port $${DASHBOARD_PORT:-8501}
```

---

## Exemplos de Configs (`configs/*.yaml`)

### `configs/data.yaml`

```yaml
path_raw: data/raw
path_processed: data/processed
index_col: timestamp
symbol: "BTCUSDT"
timezone: "UTC"   # timezone-aware obrigat√≥rio
units:
  returns: "log"
  costs: "bps"
features:
  - rsi_14
  - zscore_60
  - vol_30
  - mom_20
label:
  kind: classification
  horizon: 15m
  rule: future_return_gt_0
split:
  method: walk_forward
  n_splits: 5
  embargo: 5   # barras
schema_version: 1
```

### `configs/xgb.yaml`

```yaml
seed: 42
cv: purged_kfold
cv_params:
  n_splits: 5
  embargo: 5
xgb:
  n_estimators: 500
  learning_rate: 0.05
  max_depth: 6
  subsample: 0.8
  colsample_bytree: 0.8
optuna:
  enabled: false
  n_trials: 50
costs:
  fee_bps: 5
  slippage_bps: 5
```

### `configs/lstm.yaml`

```yaml
seed: 42
window: 128
stride: 1
batch_size: 256
epochs: 50
lr: 1e-3
hidden_size: 64
num_layers: 2
dropout: 0.2
optimizer: adam
scheduler: cosine
val_patience: 5
scaler: standard   # fitado no treino
deterministic: true
gradient_clipping: 1.0
weight_decay: 1e-4
```

### `configs/backtest.yaml`

```yaml
initial_capital: 100000
position_mode: long_short
execution:
  rule: next_bar_open     # sinal em t, execu√ß√£o na abertura de t+1
  partial_fills: false
  min_lot: 0.0001
  price_reference: open
risk:
  max_leverage: 1.0
  kelly_fraction: 0.25
costs:
  fee_bps: 5
  slippage_bps: 10
  funding_apr_est: 0.00   # funding anualizado estimado (pr√≥-rata por barra)
  borrow_apr_est: 0.00    # custo de short sint√©tico quando aplic√°vel
sizing:
  method: volatility_target
  vol_target: 0.2
  lookback: 60
trading_hours:
  start: "00:00"
  end: "23:59"
```

### `configs/agent.yaml` (guardrails)

```yaml
agent:
  max_edits: 8
  max_runtime_min: 12
  test_timeout_s: 180
  fast_flags:
    train_xgb: "--fast"
    train_lstm: "--fast"
  allowed_dirs: ["src","configs","tests","AI_MEMORY.md","CODE_MAP.md","EXPERIMENTS.md"]
  banned_paths: ["data/raw/**","artifacts/mlruns/**"]
  gpu: false
```

---

## Especifica√ß√£o do Backtest

* **Calend√°rio**: usar timestamps do dataset; filtrar buracos e consolidar barras.
* **Sinal para posi√ß√£o**: limiariza√ß√£o de probabilidade calibrada (ou z-score do retorno esperado).
* **Execu√ß√£o**: **t+1** na abertura; aplicar slippage e fees; sem ‚Äúclose-to-close‚Äù.
* **Custos**: fee + slippage + funding/borrow. Transa√ß√µes somente quando h√° mudan√ßa de posi√ß√£o.
* **Relat√≥rios**: equity, MDD, retorno anualizado, heatmap por m√™s, distribui√ß√£o de retornos, turnover, exposi√ß√£o m√©dia.
* **Overfit flag**: marcar se Sharpe OOS ‚â™ IS; registrar nota honesta no scorecard.

---

## Interpretabilidade

* **XGB**: Tree SHAP (exato para √°rvores); permuta√ß√£o global.
* **Estabilidade**: reportar m√©dia e **desvio-padr√£o** das top‚Äëk import√¢ncias entre *folds*.
* **PDP/ICE**: somente em valida√ß√£o; salvar em MLflow.

---

## Labeling

* **Fixed horizon** (simples) e **Triple‚ÄëBarrier** (padr√£o quando a meta envolve risco/retorno com stop/TP/timeout).

---

## MLOps

* **MLflow**: artefatos (modelos, figuras), par√¢metros e m√©tricas. Nomear runs por `symbol/model/horizon`. Tags obrigat√≥rias: `git_commit`, `dataset_sha256`, `config_sha256`, `degraded_mode`, `prd_name`, `prd_version`, `prd_sha256`, `exec_rule`.
* **Model Registry**: adotar **champion/challenger**; promover somente com melhora OOS consistente e risco n√£o piorado.
* **DVC** (opcional): versionar `data/raw` e `data/processed`; remoto S3-compat√≠vel.
* **CI**: pipeline com lint, tipos, testes, *smoke* do dashboard, treinos r√°pidos de XGB e LSTM e verifica√ß√£o de determinismo.
* **Produ√ß√£o (quando aplic√°vel)**: monitorar *data drift* (PSI/KL), *prediction drift*, *latency* e *error rate*; alertas com thresholds.
* **Retraining**: janela m√≥vel e *champion/challenger*; promover se Sharpe OOS melhora e risco n√£o piora.

### DVC Quickstart

```
dvc remote add -d s3remote s3://<bucket>/<key>
dvc add data/processed
dvc push -r s3remote
```

### GitHub Actions (exemplo)

```yaml
name: ci
on: [push, pull_request]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: {python-version: '3.11'}
      - run: pip install -U pip && pip install .[dev]
      - run: make deterministic
      - run: ruff check . && ruff format --check . && black --check .
      - run: mypy src
      - run: pip-audit -r requirements.txt --strict
      - run: gitleaks detect --no-git --redact || true
      - run: pytest -q
      - name: Smoke - treino r√°pido XGB
        run: python -m src.models.xgb --config configs/xgb.yaml --fast
      - name: Smoke - treino r√°pido LSTM
        run: python -m src.models.lstm --config configs/lstm.yaml --fast
      - name: Smoke - dashboard
        run: |
          python - <<'PY'
          import importlib
          importlib.import_module('src.dashboard.app')
          print('dashboard import ok')
          PY
      - name: Dataset & env hashes
        run: |
          python - <<'PY'
          import hashlib, pkgutil, sys
          from pathlib import Path
          p=Path('data/processed'); h=hashlib.sha256()
          [ h.update(f.read_bytes()) for f in sorted(p.rglob('*.parquet')) ]
          print('DATASET_SHA256=',h.hexdigest())
          print('PYTHON_VERSION=',sys.version.split()[0])
          print('PKGS=',len(list(pkgutil.iter_modules())))
          PY
```

---

## Dashboard (p√°ginas)

1. **Vis√£o Geral**: par√¢metros da run, m√©tricas, tabela de runs MLflow com filtro.
2. **Curvas**: equity, drawdown, rolling Sharpe.
3. **Classifica√ß√£o**: matriz de confus√£o, PR/ROC, **Threshold Tuning/EV** com slider e curva de EV l√≠quido.
4. **Atribui√ß√£o**: import√¢ncias, PDP/ICE, abla√ß√£o de features.
5. **Regimes**: performance por volatilidade/hor√°rio/sess√£o.
6. **Compare Runs**: overlay de equities entre duas runs.
7. **Backtest**: opera√ß√µes, turnover, heatmap de retornos por per√≠odo.

---

## Entrypoints esperados

* `python -m src.models.xgb --config configs/xgb.yaml`
* `python -m src.models.lstm --config configs/lstm.yaml`
* `python -m src.backtest.engine --config configs/backtest.yaml`
* `streamlit run src/dashboard/app.py`

---

## Roadmap sugerido

1. Baselines e backtest confi√°vel com custos e execu√ß√£o t+1.
2. XGB com PurgedKFold e Optuna leve.
3. LSTM com janelas, regulariza√ß√£o forte e determinismo habilitado.
4. Dashboard conectado ao MLflow.
5. CI completa, lock de deps e DVC remoto.

---

## Checklist por Tarefa

* [ ] Plano e aceita√ß√£o em `AI_MEMORY.md`.
* [ ] C√≥digo com type hints e docstrings.
* [ ] Testes atualizados e passando; valida√ß√µes `pandera` OK.
* [ ] Lints, tipos, seguran√ßa OK; **pip-audit** e **gitleaks** limpos; lock presente.
* [ ] **Calibra√ß√£o + threshold** executados (F1/PR‚ÄëAUC) e **`th_ev`** por EV l√≠quido reportado; **Brier** reportado.
* [ ] Artefatos no `artifacts/` e log no MLflow; tags preenchidas, incluindo `prd_*` e `exec_rule`.
* [ ] Mem√≥ria e mapas atualizados.
* [ ] Commit convencional e, se aplic√°vel, DVC atualizado.

---

## Troubleshooting (r√°pido)

* **"Temporal leakage detected"**: revise `embargo`, checagem de janelas e se algum `fit()` escapou para valida√ß√£o/teste.
* **"Sharpe baixo OOS"**: aumente custos realistas, reduza turnover, reavalie threshold e regulariza√ß√£o.
* **"MLflow n√£o loga"**: verifique `MLFLOW_TRACKING_URI` e permiss√µes de escrita.
* **"Dashboard n√£o abre"**: teste import (`import src.dashboard.app`) e depend√™ncias.
* **"Resultados n√£o reproduzem"**: valide `make deterministic`, seeds, vers√£o de libs e hardware (CPU vs GPU).
* **"Timezone/Unidades"**: garanta `UTC` e contrato `{returns: log, costs: bps}`.
* **"Lock ausente ou desatualizado"**: regenere `requirements.txt` com hashes e recommite.

---

## Ap√™ndice A ‚Äî Conven√ß√µes de mensagem de commit

* `feat(model): add xgb with purged kfold and mlflow logging`
* `refactor(features): unify rolling window transforms`
* `fix(backtest): correct slippage application on trade open`

## Ap√™ndice B ‚Äî Placeholders de C√≥digo (stubs)

```python
# src/utils/config.py
from pydantic_settings import BaseSettings
class Settings(BaseSettings):
    mlflow_uri: str = "artifacts/mlruns"
    class Config:
        env_file = ".env"
settings = Settings()
```

```python
# src/utils/logging.py
import structlog
structlog.configure(processors=[structlog.processors.TimeStamper(fmt="iso"), structlog.processors.JSONRenderer()])
log = structlog.get_logger()
```

```python
# src/data/schema.py
import pandera as pa
from pandera import DataFrameSchema, Column, Check
BarsSchema = DataFrameSchema({
  "timestamp": Column(pa.Timestamp, checks=[Check.is_monotonic_increasing()]),
  "open": Column(float, checks=Check.ge(0)),
  "high": Column(float, checks=Check.ge(0)),
  "low":  Column(float, checks=Check.ge(0)),
  "close":Column(float, checks=Check.ge(0)),
  "volume": Column(float, checks=Check.ge(0)),
}, coerce=True)
```

```python
# src/data/splits.py (Purged K-Fold com embargo, stub funcional)
from typing import Iterator, Tuple
import numpy as np, pandas as pd

def purged_kfold_index(times: pd.Series, n_splits=5, embargo=0) -> Iterator[Tuple[np.ndarray,np.ndarray]]:
    idx = np.arange(len(times))
    folds = np.array_split(idx, n_splits)
    for val in folds:
        val_start, val_end = val[0], val[-1]
        mask = (idx <= val_start - embargo) | (idx >= val_end + embargo)
        train = idx[mask]
        yield train, val
```

```python
# src/features/labels.py (Triple-Barrier)
def triple_barrier(close, pt=0.01, sl=0.01, max_h=60):
    """Retorna labels {-1,0,1} por barra sem olhar al√©m de max_h."""
    ...
```

```python
# src/models/postproc.py (calibra√ß√£o + threshold por EV)
from sklearn.calibration import CalibratedClassifierCV

def calibrate_and_threshold(model, X_tr, y_tr, X_val, y_val, costs, target="f1"):
    """Ajusta calibrador (isot√¥nico/Platt) e retorna calibrador + thresholds (f1/prauc/ev)."""
    ...

def choose_threshold_by_ev(p_val, y_val, costs, clip=(0,1)):
    import numpy as np
    cand = np.linspace(0.05, 0.95, 181)
    def ev(th):
        side = (p_val >= th).astype(int)*2-1
        gross = expected_return_proxy(side, y_val)  # seu proxy
        net = gross - turnover(side)*costs.total_bps/1e4
        return net.mean()
    th = max(cand, key=ev)
    return float(np.clip(th, *clip))
```

---

# üîß ADDENDUM ‚Äî Opera√ß√£o Claude Code sob Controle Total

## 1) Contrato de Resposta do Agente

O agente **sempre** responde neste formato por tarefa:

```
=== PLAN ===
goal: <uma frase verific√°vel>
steps:
  - read: <arquivos-alvo>
  - edit: <arquivos/fun√ß√µes-alvo>
  - run: <comandos exatos de verifica√ß√£o>
risks: [leakage, custo, lat√™ncia, flakiness]
done_when:
  - <checks objetivos observ√°veis>
refs:
  prd:
    file: docs/prd/PRD_XGB.md
    version: 1.2.0
    sha256: 4e6c‚Ä¶9b
=== /PLAN ===

=== DIFF ===
# √öNICO patch unificado, edi√ß√£o m√≠nima.
--- a/src/...
+++ b/src/...
@@ ...
=== /DIFF ===

=== RUN ===
make deterministic
make type
make test
python -m src.models.xgb --config configs/xgb.yaml --fast
python -m src.models.lstm --config configs/lstm.yaml --fast
python -m src.backtest.engine --config configs/backtest.yaml --fast
=== /RUN ===

=== MEMORY_UPDATE(JSON) ===
{ "ts": "<UTC ISO>", "task": "<slug>",
  "touched": ["src/..."], "entrypoints_added": [],
  "configs_changed": ["configs/..."],
  "mlflow": {"run_id": null, "tags": {"degraded_mode": false}},
  "notes": "porqu√™s, trade-offs, TODO imediato" }
=== /MEMORY_UPDATE ===
```

## 2) Auto-QA do Agente (Scorecard obrigat√≥rio)

Salvar em `artifacts/reports/last_scorecard.txt` e imprimir no fim da resposta:

```
=== AGENT_SCORECARD ===
data_contracts: pass|fail
temporal_leak_checks: pass|fail
determinism: pass|fail
tests(pytest): <X> passed, <Y> failed
lint(type): ruff 0 warn, mypy 0 err, audit 0 vuln
ml_metrics: {"F1": ..., "PR-AUC": ..., "MCC": ..., "Brier": ...}
trading_metrics: {"Sharpe": ..., "MDD": ..., "turnover": ..., "EV_val_net": ...}
risk_notes: "<1 linha honesta>"
=== /AGENT_SCORECARD ===
```

Se falhar, o agente deve responder com um novo `=== PLAN ===` de corre√ß√£o.

---

## PRDs persistentes e Instru√ß√µes de Projeto (Claude Projects)

1. **Base de conhecimento**: suba `PRD_XGB.md` e `PRD_LSTM.md` no **Project** para recupera√ß√£o autom√°tica.
2. **Project Instructions**: cravar regra:

```
Regra de PRD (obrigat√≥ria):
- Sempre identificar o modelo-alvo (XGBoost ou LSTM) e CONSULTAR o PRD correspondente antes de planejar, editar ou treinar.
- O plano (=== PLAN ===) deve citar explicitamente: PRD: <arquivo> | vers√£o <semver> | sha256 <hash curto>
- Se o PRD estiver ausente/desatualizado, parar e pedir corre√ß√£o.
- N√£o avaliar resultados de teste sem cumprir o PRD.
```

3. **Mem√≥ria no reposit√≥rio**: bloco fixo ‚ÄúPRD Registry‚Äù em `AI_MEMORY.md`:

```yaml
## PRD Registry
- name: PRD_XGB
  path: docs/prd/PRD_XGB.md
  version: 1.2.0
  sha256: 4e6c‚Ä¶9b
- name: PRD_LSTM
  path: docs/prd/PRD_LSTM.md
  version: 1.1.3
  sha256: a91d‚Ä¶07
```

4. **Model Registry/MLflow**: logar `prd_name`, `prd_version`, `prd_sha256` em toda run.

---

> **Resumo**: m√©todo acima de brilho. Com determinismo, execu√ß√£o t+1, custos completos e threshold por EV, n√£o h√° Sharpe ‚Äúde papel‚Äù. √â pesquisa que se sustenta na segunda-feira de manh√£.
